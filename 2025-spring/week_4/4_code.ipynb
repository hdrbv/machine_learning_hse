{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc5a9b0",
   "metadata": {},
   "source": [
    "# План семинара\n",
    "- Функционалы и метрики\n",
    "- Кросс-валидация\n",
    "- Переобучение и регуляризация\n",
    "- Гиперпараметры и их оптимизация\n",
    "- Линейный классификатор в задаче бинарной классификации\n",
    "- Кодирование категориальных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5ed40",
   "metadata": {},
   "source": [
    "# Функционалы и метрики\n",
    "\n",
    "Quick recap\n",
    "\n",
    "Функционал (или функция потерь == loss function)  - это функция, позволяющая обучить модель (то есть то, что мы стараемся оптимизировать, подбирая параметры модели - в случае линейной регрессии параметры - это веса)\n",
    "\n",
    "Метрика - это оценка качества модели, которую можно использовать к любым моделям (позволяет ответить на вопрос, насколько точно модель может предсказывать целевую переменную)\n",
    "\n",
    "Пример: Чтобы обучить линейную регрессию мы можем минизировать функционал MSE\n",
    "\n",
    "Если мы имеем n наблюдений и k признаков\n",
    "\n",
    "$\\Sigma_{i=0}^{n}(\\hat y_{i} - y_{i})^{2} \\rightarrow min_{w}$\n",
    "\n",
    "где $\\hat y_{i} = \\Sigma_{i=0}^{k}w_{k}X_{ik}$\n",
    "\n",
    "А как метрику можем использовать RMSE\n",
    "\n",
    "$RMSE = \\sqrt{\\Sigma_{i=0}^{n}(\\hat y_{i} - y_{i})^{2}}$\n",
    "\n",
    "Фундаментальное различие функционала и метрик в том, что метрика должна отражать нашу бизнес-задачу или научный вопрос, а функционал должен быть подобран так, чтобы он лучше лучше всего помогал достичь цель (позволял достичь наилучшных показателей метрики или метрик)\n",
    "\n",
    "Аналогия из обучения в вышке: Чтобы сдать матан, мы можем учить производные различных функций, то есть тогда наш функционал - это количество производных, которые мы знаем. А метрикой того, что мы сдали матан будет являться оценка, полученная в конце курса.\n",
    "\n",
    "Оценка в курсе - это понятная метрика, которую нам дал мир. А является ли зубрежка производных лучшим функционалом для достижения поставленной цели решать уже вам, как исследователям\n",
    "\n",
    "И еще, хотя функционал и метрики - это разные по смыслу и использованию инструменты, они могут быть считаться одинаково (то есть к примеру обучать линейную регрессию можно обучать с помощью функционала MSE, и проверять качество тоже можно с помощью MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf0cd6af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:51.857595Z",
     "start_time": "2021-09-20T20:03:51.853794Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.datasets import load_diabetes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479241c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:51.868197Z",
     "start_time": "2021-09-20T20:03:51.860440Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6afdc27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:51.891504Z",
     "start_time": "2021-09-20T20:03:51.889057Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "818d9dff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:51.921761Z",
     "start_time": "2021-09-20T20:03:51.893244Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_diabetes(return_X_y = True, as_frame = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "705ca49c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:51.942848Z",
     "start_time": "2021-09-20T20:03:51.923438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018114</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046883</td>\n",
       "      <td>0.015491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044529</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081413</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004222</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  \n",
       "0   -0.002592  0.019907 -0.017646  \n",
       "1   -0.039493 -0.068332 -0.092204  \n",
       "2   -0.002592  0.002861 -0.025930  \n",
       "3    0.034309  0.022688 -0.009362  \n",
       "4   -0.002592 -0.031988 -0.046641  \n",
       "..        ...       ...       ...  \n",
       "437 -0.002592  0.031193  0.007207  \n",
       "438  0.034309 -0.018114  0.044485  \n",
       "439 -0.011080 -0.046883  0.015491  \n",
       "440  0.026560  0.044529 -0.025930  \n",
       "441 -0.039493 -0.004222  0.003064  \n",
       "\n",
       "[442 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e6e3ca3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:51.955438Z",
     "start_time": "2021-09-20T20:03:51.947473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      151.0\n",
       "1       75.0\n",
       "2      141.0\n",
       "3      206.0\n",
       "4      135.0\n",
       "       ...  \n",
       "437    178.0\n",
       "438    104.0\n",
       "439    132.0\n",
       "440    220.0\n",
       "441     57.0\n",
       "Name: target, Length: 442, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27aed23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_diabetes in module sklearn.datasets._base:\n",
      "\n",
      "load_diabetes(*, return_X_y=False, as_frame=False, scaled=True)\n",
      "    Load and return the diabetes dataset (regression).\n",
      "    \n",
      "    ==============   ==================\n",
      "    Samples total    442\n",
      "    Dimensionality   10\n",
      "    Features         real, -.2 < x < .2\n",
      "    Targets          integer 25 - 346\n",
      "    ==============   ==================\n",
      "    \n",
      "    .. note::\n",
      "       The meaning of each feature (i.e. `feature_names`) might be unclear\n",
      "       (especially for `ltg`) as the documentation of the original dataset is\n",
      "       not explicit. We provide information that seems correct in regard with\n",
      "       the scientific literature in this field of research.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <diabetes_dataset>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    return_X_y : bool, default=False\n",
      "        If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "        See below for more information about the `data` and `target` object.\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "    \n",
      "    as_frame : bool, default=False\n",
      "        If True, the data is a pandas DataFrame including columns with\n",
      "        appropriate dtypes (numeric). The target is\n",
      "        a pandas DataFrame or Series depending on the number of target columns.\n",
      "        If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
      "        DataFrames or Series as described below.\n",
      "    \n",
      "        .. versionadded:: 0.23\n",
      "    \n",
      "    scaled : bool, default=True\n",
      "        If True, the feature variables are mean centered and scaled by the\n",
      "        standard deviation times the square root of `n_samples`.\n",
      "        If False, raw data is returned for the feature variables.\n",
      "    \n",
      "        .. versionadded:: 1.1\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    data : :class:`~sklearn.utils.Bunch`\n",
      "        Dictionary-like object, with the following attributes.\n",
      "    \n",
      "        data : {ndarray, dataframe} of shape (442, 10)\n",
      "            The data matrix. If `as_frame=True`, `data` will be a pandas\n",
      "            DataFrame.\n",
      "        target: {ndarray, Series} of shape (442,)\n",
      "            The regression target. If `as_frame=True`, `target` will be\n",
      "            a pandas Series.\n",
      "        feature_names: list\n",
      "            The names of the dataset columns.\n",
      "        frame: DataFrame of shape (442, 11)\n",
      "            Only present when `as_frame=True`. DataFrame with `data` and\n",
      "            `target`.\n",
      "    \n",
      "            .. versionadded:: 0.23\n",
      "        DESCR: str\n",
      "            The full description of the dataset.\n",
      "        data_filename: str\n",
      "            The path to the location of the data.\n",
      "        target_filename: str\n",
      "            The path to the location of the target.\n",
      "    \n",
      "    (data, target) : tuple if ``return_X_y`` is True\n",
      "        Returns a tuple of two ndarray of shape (n_samples, n_features)\n",
      "        A 2D array with each row representing one sample and each column\n",
      "        representing the features and/or target of a given sample.\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.datasets import load_diabetes\n",
      "    >>> diabetes = load_diabetes()\n",
      "    >>> diabetes.target[:3]\n",
      "    array([151.,  75., 141.])\n",
      "    >>> diabetes.data.shape\n",
      "    (442, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(load_diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34af39c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 442\\n\\n:Number of Attributes: First 10 columns are numeric predictive values\\n\\n:Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n:Attribute Information:\\n    - age     age in years\\n    - sex\\n    - bmi     body mass index\\n    - bp      average blood pressure\\n    - s1      tc, total serum cholesterol\\n    - s2      ldl, low-density lipoproteins\\n    - s3      hdl, high-density lipoproteins\\n    - s4      tch, total cholesterol / HDL\\n    - s5      ltg, possibly log of serum triglycerides level\\n    - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_diabetes().DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "093f5695",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:51.962949Z",
     "start_time": "2021-09-20T20:03:51.957145Z"
    }
   },
   "outputs": [],
   "source": [
    "# Разобьем данные на обучающую и тестовую выборки\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912f1b35",
   "metadata": {},
   "source": [
    "Как было рассказано на лекции, линейную регрессию можно обучать с помощью разного функционала (не только MSE, который мы разбирали на прошлом семинаре) и оценивать с помощью разных метрик - закодим это "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b266dd96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:52.207120Z",
     "start_time": "2021-09-20T20:03:51.964240Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "lr_mse = SGDRegressor(loss = 'squared_error', max_iter = 50000)\n",
    "lr_mae = SGDRegressor(loss = 'epsilon_insensitive', epsilon = 0, max_iter = 50000)\n",
    "\n",
    "lr_mse.fit(X_train, y_train)\n",
    "lr_mae.fit(X_train, y_train)\n",
    "\n",
    "y_pred_mse = lr_mse.predict(X_test)\n",
    "y_pred_mae = lr_mae.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1eda72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145.246124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174.493163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143.797521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>283.512824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131.291917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0  145.246124\n",
       "1  174.493163\n",
       "2  143.797521\n",
       "3  283.512824\n",
       "4  131.291917"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred_mse).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dc9ff74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss: \n",
      "mae=41.7114314553139\n",
      "mse=2811.3971376732493\n",
      "R2=0.49158140141281137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''MSE loss: \n",
    "mae={mean_absolute_error(y_test, y_pred_mse)}\n",
    "mse={mean_squared_error(y_test, y_pred_mse)}\n",
    "R2={r2_score(y_test, y_pred_mse)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a1aeb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE loss: \n",
      "mae=62.88158974548468\n",
      "mse=5566.6446105480045\n",
      "R2=-0.006682981142266842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''MAE loss: \n",
    "mae={mean_absolute_error(y_test, y_pred_mae)}\n",
    "mse={mean_squared_error(y_test, y_pred_mae)}\n",
    "R2={r2_score(y_test, y_pred_mae)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19825a90",
   "metadata": {},
   "source": [
    "Как мы говорили раньше, метрика должна отражать реальную цель из мира, поэтому нередко возникает потребность в написании своих собственных метрик, которые лучше описывают вашу конретную реальность. В задачах, связанных с медициной (как у нас сейчас), довольно высокая цена ошибки (у человека есть диабет, а мы его не нашли). Поэтому для того, чтобы ответить на вопрос, можно ли модель использовать в жизни, имеет смысл использовать метрику максимальной ошибки модели\n",
    "\n",
    "$max error = max(|\\hat y_{i} - y_{i}|)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0af21500",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:52.213290Z",
     "start_time": "2021-09-20T20:03:52.208515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 136.7995405018492\n",
      "MAE Loss: 175.53165914194616\n"
     ]
    }
   ],
   "source": [
    "def max_error(y_true, y_pred):\n",
    "    max_error = np.abs(y_true - y_pred).max()\n",
    "    return max_error\n",
    "\n",
    "def quantile_error(y_true, y_pred, q = 0.95):\n",
    "    q_error = np.quantile(np.abs(y_true -  y_pred), q)\n",
    "    return q_error\n",
    "\n",
    "# Оценим максимальную ошибку в обоих случаях\n",
    "\n",
    "print(f'MSE Loss: {max_error(y_test, y_pred_mse)}')\n",
    "print(f'MAE Loss: {max_error(y_test, y_pred_mae)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbc9291",
   "metadata": {},
   "source": [
    "BTW, в sklearn есть большое количество уже реализованных метрик - можете посмотреть их список и варианты применения здесь\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb1ad2",
   "metadata": {},
   "source": [
    "#  Кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9107f201",
   "metadata": {},
   "source": [
    "Когда выбран функционал и метрика, можно задаться вопросом: а насколько я могу доверять полученным результатам (значениям метрики), не являются ли они случайностями или совпадением? Кросс-валидация - это инструмент для ответа на этот вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "316b94f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:52.216719Z",
     "start_time": "2021-09-20T20:03:52.214661Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244c3991",
   "metadata": {},
   "source": [
    "здесь можно посмотреть какие параметры требуются для этой функции\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05b21625",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:53.112215Z",
     "start_time": "2021-09-20T20:03:52.218043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mse errors are [-3000.68112445 -3037.54744157 -3167.14785392 -2896.14875641\n",
      " -3017.71294922]\n",
      "mean test mse = -3023.8476251126585\n"
     ]
    }
   ],
   "source": [
    "# проверим на кросс-валидации значения ошибок MSE, MAE, R2 \n",
    "# для линейной регрессии, обученной с помощью функционала MSE\n",
    "\n",
    "num_splits = 5\n",
    "\n",
    "cv_res = cross_validate(lr_mse,\n",
    "                     X,\n",
    "                     y,\n",
    "                     scoring = 'neg_mean_squared_error', # метрика, которую нужно оценить\n",
    "                     cv = num_splits # количество разбиений или класс-сплиттер\n",
    "                    )\n",
    "\n",
    "print(f\"test mse errors are {cv_res['test_score']}\")\n",
    "print(f\"mean test mse = {cv_res['test_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab5906ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:54.005611Z",
     "start_time": "2021-09-20T20:03:53.114755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mse errors are [-2979.5690195  -3042.04669763 -3158.2106058  -2903.80036464\n",
      " -3039.5722748 ] \n",
      "and  mean mse = -3024.6397924759885\n",
      "\n",
      "test mae errors are [-44.96889504 -44.98651586 -47.97754531 -42.71112063 -44.01910415] \n",
      "and  mean mae = -44.93263619612895\n",
      "\n",
      "test R2 are [0.38858863 0.52051719 0.49537942 0.44650172 0.53025678] \n",
      "and  mean R2 = 0.4762487459081096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проведем кросс-валидацию сразу для нескольких метрик\n",
    "\n",
    "cv_res2 = cross_validate(lr_mse,\n",
    "                     X,\n",
    "                     y,\n",
    "                     scoring = ['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2'],\n",
    "                     cv = num_splits\n",
    "                    )\n",
    "print(f\"\"\"test mse errors are {cv_res2['test_neg_mean_squared_error']} \n",
    "and  mean mse = {cv_res2['test_neg_mean_squared_error'].mean()}\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"test mae errors are {cv_res2['test_neg_mean_absolute_error']} \n",
    "and  mean mae = {cv_res2['test_neg_mean_absolute_error'].mean()}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "print(f\"\"\"test R2 are {cv_res2['test_r2']} \n",
    "and  mean R2 = {cv_res2['test_r2'].mean()}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cb5c351",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:54.925817Z",
     "start_time": "2021-09-20T20:03:54.007607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-136.10881943, -161.08184672, -120.50815719, -128.65788561,\n",
       "       -135.47853836])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# для тех, кто хочет хочет дополнительно подумать\n",
    "\n",
    "# кросс-валидацию можно проводить на основе своей кастомной метрики, но для этого\n",
    "# из нее нужно сделать объект scorer\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "max_error_scorer = make_scorer(max_error, greater_is_better = False)\n",
    "\n",
    "cv_res3 = cross_validate(lr_mse,\n",
    "                     X,\n",
    "                     y,\n",
    "                     scoring = max_error_scorer,\n",
    "                     cv = num_splits\n",
    "                    )\n",
    "cv_res3['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e17c6",
   "metadata": {},
   "source": [
    "# Немного feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c235d",
   "metadata": {},
   "source": [
    "Один из самых главных источников улучшения качества прогноза модели - это информативный набор признаков. Поэтому в попытке улучшить качество нашей модели обогатим наше признаковое пространство попарными произведениями признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f268b47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:54.996285Z",
     "start_time": "2021-09-20T20:03:54.927938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>...</th>\n",
       "      <th>s6_x_age</th>\n",
       "      <th>s6_x_sex</th>\n",
       "      <th>s6_x_bmi</th>\n",
       "      <th>s6_x_bp</th>\n",
       "      <th>s6_x_s1</th>\n",
       "      <th>s6_x_s2</th>\n",
       "      <th>s6_x_s3</th>\n",
       "      <th>s6_x_s4</th>\n",
       "      <th>s6_x_s5</th>\n",
       "      <th>s6_x_s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000672</td>\n",
       "      <td>-0.000894</td>\n",
       "      <td>-0.001089</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>0.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>0.004746</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>-0.006861</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.008502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002212</td>\n",
       "      <td>-0.001314</td>\n",
       "      <td>-0.001153</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>0.000672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>-0.000321</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000251</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>-0.001020</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.000727</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.002175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018114</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>-0.000708</td>\n",
       "      <td>-0.003009</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>-0.001276</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>-0.000806</td>\n",
       "      <td>0.001979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046883</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>-0.000246</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.000387</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>-0.000726</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044529</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>-0.001013</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000423</td>\n",
       "      <td>-0.000396</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>-0.000689</td>\n",
       "      <td>-0.001155</td>\n",
       "      <td>0.000672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081413</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004222</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  ...  s6_x_age  s6_x_sex  s6_x_bmi  \\\n",
       "0   -0.002592  0.019907 -0.017646  ... -0.000672 -0.000894 -0.001089   \n",
       "1   -0.039493 -0.068332 -0.092204  ...  0.000174  0.004116  0.004746   \n",
       "2   -0.002592  0.002861 -0.025930  ... -0.002212 -0.001314 -0.001153   \n",
       "3    0.034309  0.022688 -0.009362  ...  0.000834  0.000418  0.000109   \n",
       "4   -0.002592 -0.031988 -0.046641  ... -0.000251  0.002082  0.001697   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "437 -0.002592  0.031193  0.007207  ...  0.000301  0.000365  0.000142   \n",
       "438  0.034309 -0.018114  0.044485  ... -0.000245  0.002255 -0.000708   \n",
       "439 -0.011080 -0.046883  0.015491  ...  0.000646  0.000785 -0.000246   \n",
       "440  0.026560  0.044529 -0.025930  ...  0.001179  0.001158 -0.001013   \n",
       "441 -0.039493 -0.004222  0.003064  ... -0.000139 -0.000137 -0.000224   \n",
       "\n",
       "      s6_x_bp   s6_x_s1   s6_x_s2   s6_x_s3   s6_x_s4   s6_x_s5   s6_x_s6  \n",
       "0   -0.000386  0.000780  0.000614  0.000766  0.000046 -0.000351  0.000311  \n",
       "1    0.002428  0.000779  0.001767 -0.006861  0.003641  0.006300  0.008502  \n",
       "2    0.000147  0.001182  0.000887  0.000839  0.000067 -0.000074  0.000672  \n",
       "3    0.000343 -0.000114 -0.000234  0.000337 -0.000321 -0.000212  0.000088  \n",
       "4   -0.001020 -0.000184 -0.000727 -0.000380  0.000121  0.001492  0.002175  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "437  0.000431 -0.000041 -0.000018 -0.000207 -0.000019  0.000225  0.000052  \n",
       "438 -0.003009  0.002195  0.003522 -0.001276  0.001526 -0.000806  0.001979  \n",
       "439  0.000268 -0.000578 -0.000214 -0.000387 -0.000172 -0.000726  0.000240  \n",
       "440 -0.000032 -0.000423 -0.000396  0.000744 -0.000689 -0.001155  0.000672  \n",
       "441 -0.000249  0.000257  0.000085  0.000533 -0.000121 -0.000013  0.000009  \n",
       "\n",
       "[442 rows x 110 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "cols = copy.deepcopy(X.columns)\n",
    "print(cols)\n",
    "\n",
    "for col1 in cols:\n",
    "    for col2 in cols:\n",
    "        col_name = col1 + '_x_' + col2\n",
    "        if col_name not in X.columns:\n",
    "            X[col_name] = X[col1] * X[col2]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b9d73",
   "metadata": {},
   "source": [
    "# Переобучение и регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31079bbe",
   "metadata": {},
   "source": [
    "Переобучение - ситуация, когда модель хорошо выучила обучающую выборку, но при этом показывает гораздо более низкое качество точности на тестовых данных. Это можно интерпретровать как модель стала слишком специфичной и потеряла обобщающую способность\n",
    "\n",
    "В случае линеной регрессии, одним из симптомов переобучения являются высокие значения весов. С этим борются регуляризацией.\n",
    "\n",
    "Регуляризация Lasso или L1-регуляризация:\n",
    "\n",
    "$Q_{lasso}(w) = Q(w) + \\alpha \\Sigma_{j=0}^{k}|w_{k}|$\n",
    "\n",
    "Регуляризация Ridge или L2-регуляризация:\n",
    "\n",
    "$Q_{ridge}(w) = Q(w) + \\alpha \\Sigma_{j=0}^{k}w_{k}^{2}$\n",
    "\n",
    "\n",
    "Как было рассказано в лекции, несмотря на то, что оба вида регуляризации ведут к занижению значений весов, отличие регуляризации Lasso заключается в том, что она может привести часть весов к 0 (что эквивалетно безинформативности  соответствующего признака), в случае Ridge регрессии веса могут быть сколько угодно близки к 0, но никогда не равны.\n",
    "\n",
    "Объяснение в лекции :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba3352a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:55.004798Z",
     "start_time": "2021-09-20T20:03:54.997613Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6636439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:55.074878Z",
     "start_time": "2021-09-20T20:03:55.006328Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=1e-08\n",
      "Train MSE: 2390.165505772298\n",
      "Test MSE: 3949.8352119499427\n",
      "[ 1.27443044e+02 -1.50504091e+01  3.47460896e+02  4.07803941e+02\n",
      " -1.91151047e+02  1.14283421e+02 -4.60936010e+02 -4.11680738e+01\n",
      "  5.25985653e+02  8.36335981e+01  1.62594006e+03  3.33910035e+03\n",
      " -4.13183210e+02  4.32120982e+03 -7.17930959e+03  1.22403977e+03\n",
      "  6.85685374e+03  6.86524687e+03  1.21508347e+03  2.81463966e+02\n",
      " -8.12679699e+02 -5.35705044e+04 -2.04189623e+03  1.78458429e+03\n",
      "  4.95404102e+03 -2.75612102e+03 -1.80815468e+03 -6.72787942e+03\n",
      "  2.95459310e+03  1.44726042e+03 -7.47518172e+02 -8.15925232e+02\n",
      "  7.55340405e+01  2.74098104e+03 -1.22870614e+04  1.02634670e+04\n",
      "  7.24508641e+03 -9.92015397e+02  6.78605753e+03  8.20298510e+02\n",
      " -4.41745921e+02 -8.66144399e+02 -2.95940383e+02  1.03120690e+03\n",
      "  6.72415886e+03 -7.90493488e+03 -4.20156428e+03 -2.05777226e+03\n",
      " -5.48318976e+03 -5.72783891e+02 -5.57236737e+03  6.10860130e+03\n",
      " -1.17478657e+04  1.49230476e+04  2.80562765e+03  1.73946032e+02\n",
      " -1.31717694e+04 -1.66775397e+04 -6.03288787e+03  9.39189800e+03\n",
      "  1.64917723e+02 -3.00800290e+03  1.03988776e+04 -9.07866947e+03\n",
      "  7.40633582e+03 -6.70365840e+03  2.72131142e+03  2.74528732e+03\n",
      "  7.23762454e+03 -7.45757362e+03  5.09998513e+03 -5.12139339e+03\n",
      "  3.98002633e+03 -7.00947438e+03 -1.21592626e+04  1.18620968e+04\n",
      "  1.19505576e+04  1.57573775e+04  7.87952589e+03 -2.62983016e+03\n",
      "  4.68283492e+03 -2.07148899e+03  2.82046533e+03  8.00247102e+02\n",
      " -1.57374498e+03  3.72702685e+03 -1.09395767e+03  1.21887162e+04\n",
      " -1.23368471e+04  2.59616922e+03  1.75863003e+03 -2.81758924e+03\n",
      "  3.72351701e+03 -4.00351945e+03 -1.14221444e+04  1.03127663e+04\n",
      "  8.79227665e+02  1.97925847e+03  1.04173278e+04 -5.64215007e+03\n",
      "  6.77396889e+02 -5.88409643e+01 -8.57503740e+02 -1.54153889e+03\n",
      "  4.30711071e+02 -2.15659119e+03  2.34448426e+03  3.61553938e+03\n",
      "  2.56212996e+02  1.31283342e+03] \n",
      "\n",
      "alpha=0.25\n",
      "Train MSE: 3113.6015895299915\n",
      "Test MSE: 2769.3513785124137\n",
      "[   0.          -68.39332699  450.14592047  260.51267501   -0.\n",
      "   -0.         -213.68322898    0.          399.95540128    4.79109588\n",
      "    0.            0.            0.            0.           -0.\n",
      "   -0.           -0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "   -0.            0.           -0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "   -0.            0.            0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "   -0.           -0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "   -0.            0.           -0.           -0.            0.\n",
      "   -0.            0.           -0.            0.           -0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "    0.           -0.            0.           -0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "    0.            0.           -0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.        ] \n",
      "\n",
      "alpha=0.5\n",
      "Train MSE: 3347.7819965612152\n",
      "Test MSE: 2968.619845650903\n",
      "[   0.           -0.          414.64045993  171.21240508    0.\n",
      "    0.         -112.21079914    0.          365.56727981    0.\n",
      "    0.            0.            0.            0.           -0.\n",
      "   -0.           -0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "   -0.            0.           -0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "   -0.           -0.            0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "   -0.            0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "   -0.           -0.           -0.            0.            0.\n",
      "    0.            0.            0.           -0.            0.\n",
      "   -0.            0.           -0.           -0.           -0.\n",
      "    0.           -0.           -0.            0.           -0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "   -0.            0.            0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.        ] \n",
      "\n",
      "alpha=0.75\n",
      "Train MSE: 3641.7800289023417\n",
      "Test MSE: 3309.1582208491222\n",
      "[  0.          -0.         364.72123273  97.19504258   0.\n",
      "   0.         -40.24359844   0.         326.27548113   0.\n",
      "   0.           0.           0.           0.          -0.\n",
      "  -0.          -0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "   0.           0.           0.           0.          -0.\n",
      "  -0.          -0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "  -0.          -0.          -0.           0.           0.\n",
      "   0.           0.           0.          -0.           0.\n",
      "  -0.           0.          -0.          -0.          -0.\n",
      "   0.          -0.          -0.           0.          -0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.        ] \n",
      "\n",
      "alpha=1.0\n",
      "Train MSE: 4023.493131760808\n",
      "Test MSE: 3803.7769530900337\n",
      "[  0.          -0.         306.53975309  26.15850073   0.\n",
      "   0.          -0.           0.         276.35256943   0.\n",
      "   0.           0.          -0.           0.          -0.\n",
      "  -0.          -0.           0.           0.           0.\n",
      "   0.          -0.          -0.           0.           0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "  -0.          -0.           0.           0.          -0.\n",
      "  -0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "  -0.          -0.          -0.           0.           0.\n",
      "   0.           0.           0.          -0.           0.\n",
      "  -0.           0.           0.          -0.          -0.\n",
      "   0.          -0.          -0.           0.          -0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.        ] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# альфа - это гиперпараметр, посмотрим как зависят значения весов от него\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "for a in np.arange(0, 1.1, 0.25):\n",
    "    if a == 0:\n",
    "        a += 0.00000001\n",
    "    lasso = Lasso(alpha = a)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_pred_tr = lasso.predict(X_train)\n",
    "    y_pred2 = lasso.predict(X_test)\n",
    "    print('alpha={}'.format(a))\n",
    "    print('Train MSE:', mean_squared_error(y_train, y_pred_tr))\n",
    "    print('Test MSE:', mean_squared_error(y_test, y_pred2))\n",
    "    print(lasso.coef_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c171dd89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:55.133640Z",
     "start_time": "2021-09-20T20:03:55.076921Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=1e-08\n",
      "Train MSE: 2377.740038734526\n",
      "Test MSE: 3966.9167403040847\n",
      "[ 1.33826953e+02 -3.45589558e+02  3.58187558e+02  3.99780740e+02\n",
      " -8.18753939e+03  7.18046182e+03  2.50604361e+03 -1.06876839e+02\n",
      "  3.18096722e+03  9.24627695e+01  1.55792120e+03  1.18089442e+03\n",
      " -6.86418896e+02  1.92081210e+03 -5.46800277e+03 -2.94760787e-02\n",
      "  5.48794193e+03  5.59146045e+03  1.33161991e+03  5.31258627e+02\n",
      "  1.18089442e+03 -2.08683644e+00 -1.49917504e+03  4.14693304e+02\n",
      "  7.44984331e+03 -4.34274038e+03 -4.56396404e+03 -4.90918738e+03\n",
      " -4.13189444e+02  6.97673459e+02 -6.86418897e+02 -1.49917504e+03\n",
      " -4.65764124e+01  1.30117297e+03 -9.22179375e+03  7.89455956e+03\n",
      "  4.66572662e+03  1.10510086e+03  4.53759469e+03 -8.89748734e+01\n",
      "  1.92081210e+03  4.14693304e+02  1.30117297e+03  1.01534699e+03\n",
      "  9.05904073e+03 -6.94777176e+03 -5.00134377e+03 -6.88714491e+02\n",
      " -4.06838228e+03 -1.02636022e+03 -5.46800277e+03  7.44984331e+03\n",
      " -9.22179375e+03  9.05904072e+03  9.20658332e+04 -6.29038107e+04\n",
      " -5.56467133e+04 -2.62267942e+04 -3.10364134e+04  7.60558267e+03\n",
      " -2.94790560e-02 -4.34274038e+03  7.89455956e+03 -6.94777176e+03\n",
      " -6.29038107e+04  4.22231879e+04  4.02326383e+04  1.73332672e+04\n",
      "  2.39455323e+04 -7.28129407e+03  5.48794193e+03 -4.56396404e+03\n",
      "  4.66572662e+03 -5.00134377e+03 -5.56467133e+04  4.02326383e+04\n",
      "  3.15739899e+04  1.44500101e+04  1.61816684e+04 -1.13523882e+03\n",
      "  5.59146045e+03 -4.90918738e+03  1.10510086e+03 -6.88714489e+02\n",
      " -2.62267942e+04  1.73332672e+04  1.44500101e+04  1.37525224e+04\n",
      "  1.26005845e+03  3.31493332e+03  1.33161991e+03 -4.13189445e+02\n",
      "  4.53759470e+03 -4.06838228e+03 -3.10364134e+04  2.39455323e+04\n",
      "  1.61816684e+04  1.26005845e+03  2.83326713e+04 -3.81297916e+03\n",
      "  5.31258628e+02  6.97673461e+02 -8.89748733e+01 -1.02636022e+03\n",
      "  7.60558267e+03 -7.28129407e+03 -1.13523882e+03  3.31493332e+03\n",
      " -3.81297916e+03  1.44516137e+03] \n",
      "\n",
      "alpha=0.25\n",
      "Train MSE: 3023.149847335989\n",
      "Test MSE: 2851.442597483864\n",
      "[  41.69549789 -176.17119126  377.44002121  286.66534949  -40.14896248\n",
      "  -61.43684903 -223.20712585  132.07651696  330.17585847  113.34215186\n",
      "   23.1804916    26.14552972    3.2929737    24.51334136   -7.22972245\n",
      "   -9.62108851   -7.18726582    7.86514914   11.52633233   14.79579858\n",
      "   26.14552972   -1.06380661    3.29049377   12.97868698    5.47357899\n",
      "   -0.60852497    6.42454055   -2.25347598    7.32635509   12.1253161\n",
      "    3.2929737     3.29049377   25.5706478    19.39109201    4.74965458\n",
      "    5.04115113   -4.5116987     8.23170215    8.75468511   12.64357555\n",
      "   24.51334136   12.97868698   19.39109201   18.18156018    6.57281894\n",
      "    6.97188833   -3.89066668    4.4778605     7.87975378   10.3994147\n",
      "   -7.22972245    5.47357899    4.74965458    6.57281894   12.57200026\n",
      "    9.97089507    4.54430109    2.10264865    4.15750384   11.15455784\n",
      "   -9.62108851   -0.60852497    5.04115113    6.97188833    9.97089507\n",
      "    7.47391021   -0.82925061    7.02028683    4.64422242   11.27759245\n",
      "   -7.18726582    6.42454055   -4.5116987    -3.89066668    4.54430109\n",
      "   -0.82925061    3.2783527    -2.37287005    8.42444203   -4.00399347\n",
      "    7.86514914   -2.25347598    8.23170215    4.4778605     2.10264865\n",
      "    7.02028683   -2.37287005    7.81611069   -6.14323795   13.53936024\n",
      "   11.52633233    7.32635509    8.75468511    7.87975378    4.15750384\n",
      "    4.64422242    8.42444203   -6.14323795   -2.17110222    7.68285253\n",
      "   14.79579858   12.1253161    12.64357555   10.3994147    11.15455784\n",
      "   11.27759245   -4.00399347   13.53936024    7.68285253   21.16871693] \n",
      "\n",
      "alpha=0.5\n",
      "Train MSE: 3170.4772920115765\n",
      "Test MSE: 3026.5802104474537\n",
      "[  45.03310955 -126.53251435  319.81858661  239.50693887  -14.90333892\n",
      "  -41.23940723 -193.33922051  129.56814303  277.97722381  116.29367307\n",
      "   11.00920711   12.84222235    1.38498421   12.97062486   -4.73264958\n",
      "   -6.34028319   -4.06635205    3.58667477    6.23798886    7.70705404\n",
      "   12.84222235   -0.76406434    1.03269299    6.39560334    2.55633978\n",
      "   -0.64811694    3.8283447    -1.07453075    3.30814897    5.72445662\n",
      "    1.38498421    1.03269299   16.79994868   10.48928927    1.65768001\n",
      "    1.23658851   -2.63628059    4.37961521    5.51642       7.08734846\n",
      "   12.97062486    6.39560334   10.48928927   11.11080137    3.41449704\n",
      "    2.75979945   -1.54842358    2.07027391    4.8464272     5.5703915\n",
      "   -4.73264958    2.55633978    1.65768001    3.41449704    6.06115511\n",
      "    4.32880298    1.90619684    1.5756066     2.39807847    5.64991364\n",
      "   -6.34028319   -0.64811694    1.23658851    2.75979945    4.32880298\n",
      "    3.11125617    0.78705718    2.83150797    0.88160805    5.07506853\n",
      "   -4.06635205    3.8283447    -2.63628059   -1.54842358    1.90619684\n",
      "    0.78705718   -0.53802561   -0.94282183    3.44317039   -2.23594317\n",
      "    3.58667477   -1.07453075    4.37961521    2.07027391    1.5756066\n",
      "    2.83150797   -0.94282183    5.42707582   -1.76004739    7.51508078\n",
      "    6.23798886    3.30814897    5.51642       4.8464272     2.39807847\n",
      "    0.88160805    3.44317039   -1.76004739    1.40348359    4.6761628\n",
      "    7.70705404    5.72445662    7.08734846    5.5703915     5.64991364\n",
      "    5.07506853   -2.23594317    7.51508078    4.6761628    10.78048247] \n",
      "\n",
      "alpha=0.75\n",
      "Train MSE: 3312.3830247310557\n",
      "Test MSE: 3198.032916351411\n",
      "[ 4.60004088e+01 -9.60446028e+01  2.78546628e+02  2.07948613e+02\n",
      " -1.54524516e+00 -2.56032006e+01 -1.72142188e+02  1.23757891e+02\n",
      "  2.43249211e+02  1.13184889e+02  6.95404825e+00  8.39391327e+00\n",
      "  6.69376941e-01  8.87419184e+00 -3.78364064e+00 -5.03549711e+00\n",
      " -2.92289297e+00  2.15734794e+00  4.28871973e+00  5.18620008e+00\n",
      "  8.39391327e+00 -5.79963628e-01  3.46838840e-01  4.18621479e+00\n",
      "  1.60121837e+00 -6.05110914e-01  2.85832773e+00 -7.01623531e-01\n",
      "  2.00312596e+00  3.58834667e+00  6.69376941e-01  3.46838840e-01\n",
      "  1.30228397e+01  7.25658262e+00  7.08013854e-01  1.40783962e-01\n",
      " -1.90101121e+00  3.01865301e+00  4.18452807e+00  5.00593554e+00\n",
      "  8.87419184e+00  4.18621479e+00  7.25658262e+00  8.29345738e+00\n",
      "  2.25349675e+00  1.40865944e+00 -8.33201742e-01  1.26476399e+00\n",
      "  3.60001080e+00  3.77587133e+00 -3.78364064e+00  1.60121837e+00\n",
      "  7.08013854e-01  2.25349675e+00  3.93609094e+00  2.57598499e+00\n",
      "  1.08795355e+00  1.30505355e+00  1.74032650e+00  3.73616884e+00\n",
      " -5.03549711e+00 -6.05110914e-01  1.40783962e-01  1.40865944e+00\n",
      "  2.57598499e+00  1.79285237e+00  1.12013687e+00  1.56226275e+00\n",
      " -1.38221722e-01  3.04270619e+00 -2.92289297e+00  2.85832773e+00\n",
      " -1.90101121e+00 -8.33201742e-01  1.08795355e+00  1.12013687e+00\n",
      " -1.44752111e+00 -5.63512532e-01  1.91476216e+00 -1.57061896e+00\n",
      "  2.15734794e+00 -7.01623531e-01  3.01865301e+00  1.26476399e+00\n",
      "  1.30505355e+00  1.56226275e+00 -5.63512532e-01  4.45897057e+00\n",
      " -5.10883230e-01  5.31199970e+00  4.28871973e+00  2.00312596e+00\n",
      "  4.18452807e+00  3.60001080e+00  1.74032650e+00 -1.38221722e-01\n",
      "  1.91476216e+00 -5.10883230e-01  2.13739015e+00  3.46414589e+00\n",
      "  5.18620008e+00  3.58834667e+00  5.00593554e+00  3.77587133e+00\n",
      "  3.73616884e+00  3.04270619e+00 -1.57061896e+00  5.31199970e+00\n",
      "  3.46414589e+00  7.18329495e+00] \n",
      "\n",
      "alpha=1.0\n",
      "Train MSE: 3442.5630946534693\n",
      "Test MSE: 3357.0279842031478\n",
      "[ 4.56958216e+01 -7.57043433e+01  2.47419402e+02  1.84830412e+02\n",
      "  6.65351259e+00 -1.46394007e+01 -1.55826261e+02  1.17594016e+02\n",
      "  2.17566781e+02  1.08318397e+02  4.95887286e+00  6.18401970e+00\n",
      "  3.07924249e-01  6.74460276e+00 -3.23057706e+00 -4.26443825e+00\n",
      " -2.31265077e+00  1.46224899e+00  3.25505580e+00  3.88233642e+00\n",
      "  6.18401970e+00 -4.57139332e-01  5.49670270e-02  3.09037217e+00\n",
      "  1.14526151e+00 -5.47498925e-01  2.32365014e+00 -5.15670689e-01\n",
      "  1.37967057e+00  2.54214853e+00  3.07924249e-01  5.49670270e-02\n",
      "  1.07669057e+01  5.55329814e+00  2.90167828e-01 -3.07630459e-01\n",
      " -1.48731525e+00  2.31289813e+00  3.41557500e+00  3.88998835e+00\n",
      "  6.74460276e+00  3.09037217e+00  5.55329814e+00  6.70375085e+00\n",
      "  1.65175399e+00  7.85249884e-01 -5.12539092e-01  8.78104412e-01\n",
      "  2.89161019e+00  2.83035169e+00 -3.23057706e+00  1.14526151e+00\n",
      "  2.90167828e-01  1.65175399e+00  2.91865373e+00  1.78139571e+00\n",
      "  7.03599310e-01  1.14245710e+00  1.39512334e+00  2.76734425e+00\n",
      " -4.26443825e+00 -5.47498925e-01 -3.07630459e-01  7.85249884e-01\n",
      "  1.78139571e+00  1.21489732e+00  1.18773101e+00  1.00122656e+00\n",
      " -5.21124371e-01  2.06817654e+00 -2.31265077e+00  2.32365014e+00\n",
      " -1.48731525e+00 -5.12539092e-01  7.03599310e-01  1.18773101e+00\n",
      " -1.74211772e+00 -4.04783473e-01  1.21784186e+00 -1.21572360e+00\n",
      "  1.46224899e+00 -5.15670689e-01  2.31289813e+00  8.78104412e-01\n",
      "  1.14245710e+00  1.00122656e+00 -4.04783473e-01  3.88505273e+00\n",
      "  1.49075665e-02  4.14482102e+00  3.25505580e+00  1.37967057e+00\n",
      "  3.41557500e+00  2.89161019e+00  1.39512334e+00 -5.21124371e-01\n",
      "  1.21784186e+00  1.49075665e-02  2.29339233e+00  2.78048822e+00\n",
      "  3.88233642e+00  2.54214853e+00  3.88998835e+00  2.83035169e+00\n",
      "  2.76734425e+00  2.06817654e+00 -1.21572360e+00  4.14482102e+00\n",
      "  2.78048822e+00  5.36193242e+00] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# альфа - это гиперпараметр, посмотрим как зависят значения весов от него\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "for a in np.arange(0, 1.1, 0.25):\n",
    "    if a == 0:\n",
    "        a += 0.00000001\n",
    "    ridge = Ridge(alpha = a)\n",
    "    ridge.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_tr = ridge.predict(X_train)\n",
    "    y_pred2 = ridge.predict(X_test)\n",
    "\n",
    "    print('alpha={}'.format(a))\n",
    "    print('Train MSE:', mean_squared_error(y_train, y_pred_tr))\n",
    "    print('Test MSE:', mean_squared_error(y_test, y_pred2))\n",
    "    print(ridge.coef_,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb320a",
   "metadata": {},
   "source": [
    "А какой коэффициент альфа лучший ? И нужна ли здесь регуляризация ?\n",
    "\n",
    "Чтобы ответить на этот вопрос мы можем с помощью кросс-валидации перебрать различные значения альфы и выбрать лучшее значение. Этот процесс называется оптимизацией гиперпараметров. Альфа является гиперпараметром, потому что задача оптимизации функционала не позволяет найти ее оптимальное значение (в отличие от весов регрессии)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b59a75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-10, 5.55555556e-01, 1.11111111e+00, 1.66666667e+00,\n",
       "       2.22222222e+00, 2.77777778e+00, 3.33333333e+00, 3.88888889e+00,\n",
       "       4.44444444e+00, 5.00000000e+00])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(1e-10, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a04ffd86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:55.295117Z",
     "start_time": "2021-09-20T20:03:55.135370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha value is 0.025125628240201005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "n_alphas = 200\n",
    "alphas = np.linspace(1e-10, 5, n_alphas)\n",
    "\n",
    "lasso_cv = LassoCV(alphas = alphas, cv = 5, random_state = 42)\n",
    "lasso_cv.fit(X, y)\n",
    "\n",
    "print(f'Optimal alpha value is {lasso_cv.alpha_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20de9b2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:04:01.101956Z",
     "start_time": "2021-09-20T20:03:55.296894Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.025125628240201005}\n"
     ]
    }
   ],
   "source": [
    "# Более общий способ использования кросс-валидации для поиска лучшего набора гиперпараметров\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'alpha':alphas}\n",
    "#print(params)\n",
    "cv = GridSearchCV(lasso,\n",
    "                  params,\n",
    "                  scoring = 'r2',\n",
    "                  cv = num_splits\n",
    "                 )\n",
    "cv.fit(X, y)\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1542862f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
      "\n",
      "class GridSearchCV(BaseSearchCV)\n",
      " |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |  \n",
      " |  Exhaustive search over specified parameter values for an estimator.\n",
      " |  \n",
      " |  Important members are fit, predict.\n",
      " |  \n",
      " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
      " |  \"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
      " |  implemented in the estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated grid-search over a parameter grid.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_grid : dict or list of dictionaries\n",
      " |      Dictionary with parameters names (`str`) as keys and lists of\n",
      " |      parameter settings to try as values, or a list of such\n",
      " |      dictionaries, in which case the grids spanned by each dictionary\n",
      " |      in the list are explored. This enables searching over any sequence\n",
      " |      of parameter settings.\n",
      " |  \n",
      " |  scoring : str, callable, list, tuple or dict, default=None\n",
      " |      Strategy to evaluate the performance of the cross-validated model on\n",
      " |      the test set.\n",
      " |  \n",
      " |      If `scoring` represents a single score, one can use:\n",
      " |  \n",
      " |      - a single string (see :ref:`scoring_parameter`);\n",
      " |      - a callable (see :ref:`scoring`) that returns a single value.\n",
      " |  \n",
      " |      If `scoring` represents multiple scores, one can use:\n",
      " |  \n",
      " |      - a list or tuple of unique strings;\n",
      " |      - a callable returning a dictionary where the keys are the metric\n",
      " |        names and the values are the metric scores;\n",
      " |      - a dictionary with metric names as keys and callables a values.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of jobs to run in parallel.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. versionchanged:: v0.20\n",
      " |         `n_jobs` default changed from 1 to None\n",
      " |  \n",
      " |  refit : bool, str, or callable, default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      " |      scorer that would be used to find the best parameters for refitting\n",
      " |      the estimator at the end.\n",
      " |  \n",
      " |      Where there are considerations other than maximum score in\n",
      " |      choosing a best estimator, ``refit`` can be set to a function which\n",
      " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      " |      according to the returned ``best_index_`` while the ``best_score_``\n",
      " |      attribute will not be available.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``GridSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_params_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |      See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`\n",
      " |      to see how to design a custom selection strategy using a callable\n",
      " |      via `refit`.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          Support for callable added.\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, default=None\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 5-fold cross validation,\n",
      " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used. These splitters are instantiated\n",
      " |      with `shuffle=False` so the splits will be the same across calls.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      " |  \n",
      " |  verbose : int\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |      - >1 : the computation time for each fold and parameter candidate is\n",
      " |        displayed;\n",
      " |      - >2 : the score is also displayed;\n",
      " |      - >3 : the fold and candidate parameter indexes are also displayed\n",
      " |        together with the starting time of the computation.\n",
      " |  \n",
      " |  pre_dispatch : int, or str, default='2*n_jobs'\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A str, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  error_score : 'raise' or numeric, default=np.nan\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  return_train_score : bool, default=False\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |      .. versionchanged:: 0.21\n",
      " |          Default value was changed from ``True`` to ``False``\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      " |      +============+===========+============+=================+===+=========+\n",
      " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      " |                                       mask = [False False False False]...)\n",
      " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      " |                                      mask = [ True  True False False]...),\n",
      " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      " |                                       mask = [False False  True  True]...),\n",
      " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      " |          'rank_test_score'    : [2, 4, 3, 1],\n",
      " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |      This attribute is not available if ``refit`` is a function.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  refit_time_ : float\n",
      " |      Seconds used for refitting the best model on the whole dataset.\n",
      " |  \n",
      " |      This is present only if ``refit`` is not False.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  multimetric_ : bool\n",
      " |      Whether or not the scorers compute several metrics.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels. This is present only if ``refit`` is specified and\n",
      " |      the underlying estimator is a classifier.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`. Only defined if\n",
      " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
      " |      parameter for more details) and that `best_estimator_` exposes\n",
      " |      `n_features_in_` when fit.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Only defined if\n",
      " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
      " |      parameter for more details) and that `best_estimator_` exposes\n",
      " |      `feature_names_in_` when fit.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  ParameterGrid : Generates all the combinations of a hyperparameter grid.\n",
      " |  train_test_split : Utility function to split the data into a development\n",
      " |      set usable for fitting a GridSearchCV instance and an evaluation set\n",
      " |      for its final evaluation.\n",
      " |  sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
      " |      loss function.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The parameters selected are those that maximize the score of the left out\n",
      " |  data, unless an explicit score is passed in which case it is used instead.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import svm, datasets\n",
      " |  >>> from sklearn.model_selection import GridSearchCV\n",
      " |  >>> iris = datasets.load_iris()\n",
      " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      " |  >>> svc = svm.SVC()\n",
      " |  >>> clf = GridSearchCV(svc, parameters)\n",
      " |  >>> clf.fit(iris.data, iris.target)\n",
      " |  GridSearchCV(estimator=SVC(),\n",
      " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      " |  >>> sorted(clf.cv_results_.keys())\n",
      " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " |   'param_C', 'param_kernel', 'params',...\n",
      " |   'rank_test_score', 'split0_test_score',...\n",
      " |   'split2_test_score', ...\n",
      " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GridSearchCV\n",
      " |      BaseSearchCV\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,) or (n_samples, n_classes)                 or (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Result of the decision function for `X` based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  fit(self, X, y=None, **params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like of shape (n_samples, n_features) or (n_samples, n_samples)\n",
      " |          Training vectors, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features. For precomputed kernel or\n",
      " |          distance matrix, the expected shape of X is (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      **params : dict of str -> object\n",
      " |          Parameters passed to the ``fit`` method of the estimator, the scorer,\n",
      " |          and the CV splitter.\n",
      " |      \n",
      " |          If a fit parameter is an array-like whose length is equal to\n",
      " |          `num_samples` then it will be split across CV groups along with `X`\n",
      " |          and `y`. For example, the :term:`sample_weight` parameter is split\n",
      " |          because `len(sample_weights) = len(X)`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Instance of fitted estimator.\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      .. versionadded:: 1.4\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRouter\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  inverse_transform(self, X=None, Xt=None)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |          .. deprecated:: 1.5\n",
      " |              `Xt` was deprecated in 1.5 and will be removed in 1.7. Use `X` instead.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Result of the `inverse_transform` function for `Xt` based on the\n",
      " |          estimator with the best found parameters.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          The predicted labels or values for `X` based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Predicted class log-probabilities for `X` based on the estimator\n",
      " |          with the best found parameters. The order of the classes\n",
      " |          corresponds to that in the fitted attribute :term:`classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Predicted class probabilities for `X` based on the estimator with\n",
      " |          the best found parameters. The order of the classes corresponds\n",
      " |          to that in the fitted attribute :term:`classes_`.\n",
      " |  \n",
      " |  score(self, X, y=None, **params)\n",
      " |      Return the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      **params : dict\n",
      " |          Parameters to be passed to the underlying scorer(s).\n",
      " |      \n",
      " |          ..versionadded:: 1.4\n",
      " |              Only available if `enable_metadata_routing=True`. See\n",
      " |              :ref:`Metadata Routing User Guide <metadata_routing>` for more\n",
      " |              details.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          The score defined by ``scoring`` if provided, and the\n",
      " |          ``best_estimator_.score`` method otherwise.\n",
      " |  \n",
      " |  score_samples(self, X)\n",
      " |      Call score_samples on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``score_samples``.\n",
      " |      \n",
      " |      .. versionadded:: 0.24\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to predict on. Must fulfill input requirements\n",
      " |          of the underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,)\n",
      " |          The ``best_estimator_.score_samples`` method.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          `X` transformed in the new space based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |      Class labels.\n",
      " |      \n",
      " |      Only available when `refit=True` and the estimator is a classifier.\n",
      " |  \n",
      " |  n_features_in_\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |      \n",
      " |      Only available when `refit=True`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GridSearchCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f21f2d",
   "metadata": {},
   "source": [
    "## Задача бинарной классификации\n",
    "\n",
    "### Логистическая регрессия\n",
    "\n",
    "y = {-1, 1}\n",
    "\n",
    "$b(x) = \\sigma(<w,x>)$,\n",
    "\n",
    "где $\\sigma(z) = \\frac{1}{1 + e^{-z}}$\n",
    "\n",
    "То есть, мы предсказываем $P(y_i = 1| X_i)$ - вероятность того, что наблюдение принадлежит классу +1\n",
    "\n",
    "Обучаем с помощью функционала: Максимального лог правдоподобия (флэшбек из статистики)\n",
    "\n",
    "$Q(w) = -\\Sigma_{i=0}^{n}(y_i*log(b(x_i)) + (1 - y_i)log(1 - b(x_i))) \\rightarrow min_w$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b03c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc2ae7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca549dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('bike_buyers_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7de85d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Education</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Home Owner</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Commute Distance</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "      <th>Purchased Bike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12496</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>40000</td>\n",
       "      <td>1</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Skilled Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>42</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24107</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>43</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14177</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>80000</td>\n",
       "      <td>5</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Professional</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>60</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24381</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>5-10 Miles</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25597</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>30000</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>36</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>23731</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>60000</td>\n",
       "      <td>2</td>\n",
       "      <td>High School</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>54</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>28672</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>70000</td>\n",
       "      <td>4</td>\n",
       "      <td>Graduate Degree</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>35</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>11809</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>60000</td>\n",
       "      <td>2</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Skilled Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>19664</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>100000</td>\n",
       "      <td>3</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Management</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1-2 Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>38</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>12121</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>60000</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>10+ Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>53</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID Marital Status  Gender  Income  Children        Education  \\\n",
       "0    12496        Married  Female   40000         1        Bachelors   \n",
       "1    24107        Married    Male   30000         3  Partial College   \n",
       "2    14177        Married    Male   80000         5  Partial College   \n",
       "3    24381         Single    Male   70000         0        Bachelors   \n",
       "4    25597         Single    Male   30000         0        Bachelors   \n",
       "..     ...            ...     ...     ...       ...              ...   \n",
       "995  23731        Married    Male   60000         2      High School   \n",
       "996  28672         Single    Male   70000         4  Graduate Degree   \n",
       "997  11809        Married    Male   60000         2        Bachelors   \n",
       "998  19664         Single    Male  100000         3        Bachelors   \n",
       "999  12121         Single    Male   60000         3      High School   \n",
       "\n",
       "         Occupation Home Owner  Cars Commute Distance         Region  Age  \\\n",
       "0    Skilled Manual        Yes     0        0-1 Miles         Europe   42   \n",
       "1          Clerical        Yes     1        0-1 Miles         Europe   43   \n",
       "2      Professional         No     2        2-5 Miles         Europe   60   \n",
       "3      Professional        Yes     1       5-10 Miles        Pacific   41   \n",
       "4          Clerical         No     0        0-1 Miles         Europe   36   \n",
       "..              ...        ...   ...              ...            ...  ...   \n",
       "995    Professional        Yes     2        2-5 Miles  North America   54   \n",
       "996    Professional        Yes     0        2-5 Miles  North America   35   \n",
       "997  Skilled Manual        Yes     0        0-1 Miles  North America   38   \n",
       "998      Management         No     3        1-2 Miles  North America   38   \n",
       "999    Professional        Yes     2        10+ Miles  North America   53   \n",
       "\n",
       "    Purchased Bike  \n",
       "0               No  \n",
       "1               No  \n",
       "2               No  \n",
       "3              Yes  \n",
       "4              Yes  \n",
       "..             ...  \n",
       "995            Yes  \n",
       "996            Yes  \n",
       "997            Yes  \n",
       "998             No  \n",
       "999            Yes  \n",
       "\n",
       "[1000 rows x 13 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0744a18c",
   "metadata": {},
   "source": [
    "# Обзор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c846a338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                   int64\n",
       "Marital Status      object\n",
       "Gender              object\n",
       "Income               int64\n",
       "Children             int64\n",
       "Education           object\n",
       "Occupation          object\n",
       "Home Owner          object\n",
       "Cars                 int64\n",
       "Commute Distance    object\n",
       "Region              object\n",
       "Age                  int64\n",
       "Purchased Bike      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим типы колонок в датасете\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a4f289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "X.drop(columns = 'ID', inplace = True)\n",
    "\n",
    "y = data['Purchased Bike']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "146e2bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Education</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Home Owner</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Commute Distance</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>40000</td>\n",
       "      <td>1</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Skilled Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>80000</td>\n",
       "      <td>5</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Professional</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>5-10 Miles</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>30000</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Marital Status  Gender  Income  Children        Education      Occupation  \\\n",
       "0        Married  Female   40000         1        Bachelors  Skilled Manual   \n",
       "1        Married    Male   30000         3  Partial College        Clerical   \n",
       "2        Married    Male   80000         5  Partial College    Professional   \n",
       "3         Single    Male   70000         0        Bachelors    Professional   \n",
       "4         Single    Male   30000         0        Bachelors        Clerical   \n",
       "\n",
       "  Home Owner  Cars Commute Distance   Region  Age  \n",
       "0        Yes     0        0-1 Miles   Europe   42  \n",
       "1        Yes     1        0-1 Miles   Europe   43  \n",
       "2         No     2        2-5 Miles   Europe   60  \n",
       "3        Yes     1       5-10 Miles  Pacific   41  \n",
       "4         No     0        0-1 Miles   Europe   36  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cfed556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     No\n",
       "1     No\n",
       "2     No\n",
       "3    Yes\n",
       "4    Yes\n",
       "Name: Purchased Bike, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c431d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 4 numeric columns: Income, Children, Cars, Age\n",
      "And 7 categorical columns: Marital Status, Gender, Education, Occupation, Home Owner, Commute Distance, Region\n"
     ]
    }
   ],
   "source": [
    "num_cols = X.columns[X.dtypes == 'int64'].tolist()\n",
    "cat_cols = X.columns[X.dtypes == 'object']\n",
    "\n",
    "print(f\"We have {len(num_cols)} numeric columns: {', '.join(num_cols)}\")\n",
    "print(f\"And {len(cat_cols)} categorical columns: {', '.join(cat_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a849f7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marital Status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Marital Status\n",
       "Married    0.539\n",
       "Single     0.461\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gender\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "Male      0.509\n",
       "Female    0.491\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Education\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Education\n",
       "Bachelors              0.306\n",
       "Partial College        0.265\n",
       "High School            0.179\n",
       "Graduate Degree        0.174\n",
       "Partial High School    0.076\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Occupation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Occupation\n",
       "Professional      0.276\n",
       "Skilled Manual    0.255\n",
       "Clerical          0.177\n",
       "Management        0.173\n",
       "Manual            0.119\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Home Owner\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Home Owner\n",
       "Yes    0.685\n",
       "No     0.315\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Commute Distance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Commute Distance\n",
       "0-1 Miles     0.366\n",
       "5-10 Miles    0.192\n",
       "1-2 Miles     0.169\n",
       "2-5 Miles     0.162\n",
       "10+ Miles     0.111\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Region\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Region\n",
       "North America    0.508\n",
       "Europe           0.300\n",
       "Pacific          0.192\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for col in cat_cols:\n",
    "    print(col)\n",
    "    display(X[col].value_counts(normalize = True))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9384e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# у нас есть категориальные переменные разных видов!\n",
    "\n",
    "binary_cols = cat_cols[X[cat_cols].nunique() == 2].tolist()\n",
    "ordinal_cols = ['Commute Distance', 'Education']\n",
    "cat_cols = cat_cols.difference(binary_cols + ordinal_cols).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9efac8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Occupation', 'Region']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "afb1fa61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count      1000.000000\n",
       "mean      56140.000000\n",
       "std       31081.609779\n",
       "min       10000.000000\n",
       "25%       30000.000000\n",
       "50%       60000.000000\n",
       "75%       70000.000000\n",
       "max      170000.000000\n",
       "Name: Income, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Children\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean        1.908000\n",
       "std         1.626094\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         2.000000\n",
       "75%         3.000000\n",
       "max         5.000000\n",
       "Name: Children, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean        1.452000\n",
       "std         1.124705\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max         4.000000\n",
       "Name: Cars, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Age\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean       44.190000\n",
       "std        11.353537\n",
       "min        25.000000\n",
       "25%        35.000000\n",
       "50%        43.000000\n",
       "75%        52.000000\n",
       "max        89.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for col in num_cols:\n",
    "    print(col)\n",
    "    display(X[col].describe())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bf7eb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>56140.000000</td>\n",
       "      <td>1.908000</td>\n",
       "      <td>1.452000</td>\n",
       "      <td>44.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>31081.609779</td>\n",
       "      <td>1.626094</td>\n",
       "      <td>1.124705</td>\n",
       "      <td>11.353537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>170000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>89.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Income     Children         Cars          Age\n",
       "count    1000.000000  1000.000000  1000.000000  1000.000000\n",
       "mean    56140.000000     1.908000     1.452000    44.190000\n",
       "std     31081.609779     1.626094     1.124705    11.353537\n",
       "min     10000.000000     0.000000     0.000000    25.000000\n",
       "25%     30000.000000     0.000000     1.000000    35.000000\n",
       "50%     60000.000000     2.000000     1.000000    43.000000\n",
       "75%     70000.000000     3.000000     2.000000    52.000000\n",
       "max    170000.000000     5.000000     4.000000    89.000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5abb0d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Purchased Bike\n",
       "No     0.519\n",
       "Yes    0.481\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classes are balanced !\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72cc5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c47e44c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "995    1\n",
       "996    1\n",
       "997    1\n",
       "998    0\n",
       "999    1\n",
       "Name: Purchased Bike, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform y to numeric column\n",
    "y = (y == 'Yes').astype(int)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97212af5",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b99eecf",
   "metadata": {},
   "source": [
    "## Кодирование категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c340d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run if not installed yet\n",
    "\n",
    "#!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9ef0b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10f5241d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bachelors', 'Partial College', 'High School',\n",
       "       'Partial High School', 'Graduate Degree'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e65d03fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Education\n",
       "0            1\n",
       "1            2\n",
       "2            2\n",
       "3            1\n",
       "4            1\n",
       "..         ...\n",
       "995          3\n",
       "996          5\n",
       "997          1\n",
       "998          1\n",
       "999          3\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordinal: from categories to numbers\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "ord_enc.fit_transform(X['Education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0cdc5709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education_1</th>\n",
       "      <th>Education_2</th>\n",
       "      <th>Education_3</th>\n",
       "      <th>Education_4</th>\n",
       "      <th>Education_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Education_1  Education_2  Education_3  Education_4  Education_5\n",
       "0              1            0            0            0            0\n",
       "1              0            1            0            0            0\n",
       "2              0            1            0            0            0\n",
       "3              1            0            0            0            0\n",
       "4              1            0            0            0            0\n",
       "..           ...          ...          ...          ...          ...\n",
       "995            0            0            1            0            0\n",
       "996            0            0            0            0            1\n",
       "997            1            0            0            0            0\n",
       "998            1            0            0            0            0\n",
       "999            0            0            1            0            0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot: from k categories to k dummy columns\n",
    "\n",
    "one_hot_enc = OneHotEncoder()\n",
    "\n",
    "one_hot_enc.fit_transform(X['Education'], drop = 'first')\n",
    "# * fit -> определить количество новых столбцов (по кол-ву категорий)\n",
    "# * transform -> создать новые столбцы\n",
    "# * fit_transform = fit + transform\n",
    "\n",
    "# Нужно ли удалять какую-то из колонок после такого кодирования ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc35c64",
   "metadata": {},
   "source": [
    "Target encoding вычисляет значения по формуле\n",
    "\n",
    "$$\\frac{mean(target)\\cdot n_{rows} + \\alpha \\cdot globalMean}{n_{rows} + \\alpha} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1327a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.552288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.449057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.449057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.552288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.552288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.441341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.540230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.552288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.552288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.441341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Education\n",
       "0     0.552288\n",
       "1     0.449057\n",
       "2     0.449057\n",
       "3     0.552288\n",
       "4     0.552288\n",
       "..         ...\n",
       "995   0.441341\n",
       "996   0.540230\n",
       "997   0.552288\n",
       "998   0.552288\n",
       "999   0.441341\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target encoding: from k categories to posterior probabilites of y == 1 - P(y==1 | category == c1)\n",
    "\n",
    "tgt_enc = TargetEncoder(smoothing=1)\n",
    "\n",
    "# smoothing - это коэффициент сглаживания alpha, чем он больше, тем больше регуляризация\n",
    "\n",
    "tgt_enc.fit_transform(X['Education'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78773e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Education</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Home Owner</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Commute Distance</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Married</td>\n",
       "      <td>0.486762</td>\n",
       "      <td>40000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.552288</td>\n",
       "      <td>Skilled Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Married</td>\n",
       "      <td>0.475442</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.449057</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Married</td>\n",
       "      <td>0.475442</td>\n",
       "      <td>80000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.449057</td>\n",
       "      <td>Professional</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Single</td>\n",
       "      <td>0.475442</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.552288</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>5-10 Miles</td>\n",
       "      <td>0.588542</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Single</td>\n",
       "      <td>0.475442</td>\n",
       "      <td>30000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.552288</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Married</td>\n",
       "      <td>0.475442</td>\n",
       "      <td>60000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>0.433071</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Single</td>\n",
       "      <td>0.475442</td>\n",
       "      <td>70000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>0.433071</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Married</td>\n",
       "      <td>0.475442</td>\n",
       "      <td>60000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.552288</td>\n",
       "      <td>Skilled Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>0.433071</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Single</td>\n",
       "      <td>0.475442</td>\n",
       "      <td>100000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.552288</td>\n",
       "      <td>Management</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1-2 Miles</td>\n",
       "      <td>0.433071</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Single</td>\n",
       "      <td>0.475442</td>\n",
       "      <td>60000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>10+ Miles</td>\n",
       "      <td>0.433071</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Marital Status    Gender  Income  Children  Education      Occupation  \\\n",
       "0          Married  0.486762   40000         1   0.552288  Skilled Manual   \n",
       "1          Married  0.475442   30000         3   0.449057        Clerical   \n",
       "2          Married  0.475442   80000         5   0.449057    Professional   \n",
       "3           Single  0.475442   70000         0   0.552288    Professional   \n",
       "4           Single  0.475442   30000         0   0.552288        Clerical   \n",
       "..             ...       ...     ...       ...        ...             ...   \n",
       "995        Married  0.475442   60000         2   0.441341    Professional   \n",
       "996         Single  0.475442   70000         4   0.540230    Professional   \n",
       "997        Married  0.475442   60000         2   0.552288  Skilled Manual   \n",
       "998         Single  0.475442  100000         3   0.552288      Management   \n",
       "999         Single  0.475442   60000         3   0.441341    Professional   \n",
       "\n",
       "    Home Owner  Cars Commute Distance    Region  Age  \n",
       "0          Yes     0        0-1 Miles  0.493333   42  \n",
       "1          Yes     1        0-1 Miles  0.493333   43  \n",
       "2           No     2        2-5 Miles  0.493333   60  \n",
       "3          Yes     1       5-10 Miles  0.588542   41  \n",
       "4           No     0        0-1 Miles  0.493333   36  \n",
       "..         ...   ...              ...       ...  ...  \n",
       "995        Yes     2        2-5 Miles  0.433071   54  \n",
       "996        Yes     0        2-5 Miles  0.433071   35  \n",
       "997        Yes     0        0-1 Miles  0.433071   38  \n",
       "998         No     3        1-2 Miles  0.433071   38  \n",
       "999        Yes     2        10+ Miles  0.433071   53  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# энкодер можно применять сразу на весь датафрейм\n",
    "\n",
    "tgt_enc = TargetEncoder(cols=['Education', 'Gender', 'Region'])\n",
    "tgt_enc.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f77f2cb",
   "metadata": {},
   "source": [
    "## Масштабирование числовых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91ecd400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       40000\n",
       "1       30000\n",
       "2       80000\n",
       "3       70000\n",
       "4       30000\n",
       "        ...  \n",
       "995     60000\n",
       "996     70000\n",
       "997     60000\n",
       "998    100000\n",
       "999     60000\n",
       "Name: Income, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2aba0cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.76804062],\n",
       "       [ 0.44614598],\n",
       "       [-0.8414326 ],\n",
       "       [-1.48522189],\n",
       "       [ 3.34319779],\n",
       "       [-0.51953796],\n",
       "       [-1.16332725],\n",
       "       [-1.16332725],\n",
       "       [-0.8414326 ],\n",
       "       [ 1.08993527],\n",
       "       [ 3.66509243],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [-1.48522189],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [-1.16332725],\n",
       "       [-0.51953796],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [ 1.41182991],\n",
       "       [ 0.44614598],\n",
       "       [-1.16332725],\n",
       "       [-1.16332725],\n",
       "       [-1.48522189],\n",
       "       [-1.16332725],\n",
       "       [ 0.76804062],\n",
       "       [ 1.08993527],\n",
       "       [-1.48522189],\n",
       "       [-1.48522189],\n",
       "       [-0.8414326 ],\n",
       "       [-1.16332725],\n",
       "       [-1.48522189],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [-1.48522189],\n",
       "       [ 3.66509243],\n",
       "       [-1.16332725],\n",
       "       [-1.16332725],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.76804062],\n",
       "       [-1.16332725],\n",
       "       [ 1.08993527],\n",
       "       [ 0.44614598],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [ 2.37751385],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [-1.48522189],\n",
       "       [-1.48522189],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [-1.16332725],\n",
       "       [-1.48522189],\n",
       "       [ 2.0556192 ],\n",
       "       [-1.48522189],\n",
       "       [ 2.37751385],\n",
       "       [-1.16332725],\n",
       "       [-1.16332725],\n",
       "       [ 2.37751385],\n",
       "       [-1.16332725],\n",
       "       [ 0.76804062],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [-1.48522189],\n",
       "       [-0.8414326 ],\n",
       "       [-1.16332725],\n",
       "       [-0.51953796],\n",
       "       [-1.48522189],\n",
       "       [ 2.37751385],\n",
       "       [ 0.76804062],\n",
       "       [-0.8414326 ],\n",
       "       [-1.16332725],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.12425133],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [ 1.08993527],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [-0.51953796],\n",
       "       [-1.16332725],\n",
       "       [-1.48522189],\n",
       "       [ 0.12425133],\n",
       "       [-1.48522189],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [-0.51953796],\n",
       "       [-0.51953796],\n",
       "       [-1.16332725],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [ 2.37751385],\n",
       "       [-1.16332725],\n",
       "       [-1.48522189],\n",
       "       [-0.8414326 ],\n",
       "       [-1.16332725],\n",
       "       [ 0.76804062],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [ 3.02130314],\n",
       "       [ 0.76804062],\n",
       "       [ 1.41182991],\n",
       "       [-0.51953796],\n",
       "       [ 0.76804062],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [-1.48522189],\n",
       "       [-1.48522189],\n",
       "       [ 0.12425133],\n",
       "       [ 1.08993527],\n",
       "       [-0.51953796],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [-1.48522189],\n",
       "       [-1.48522189],\n",
       "       [-1.16332725],\n",
       "       [-1.16332725],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [-1.48522189],\n",
       "       [-0.51953796],\n",
       "       [ 0.76804062],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [-0.51953796],\n",
       "       [-0.51953796],\n",
       "       [-1.16332725],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.12425133],\n",
       "       [ 1.41182991],\n",
       "       [-1.16332725],\n",
       "       [ 1.41182991],\n",
       "       [ 0.76804062],\n",
       "       [-1.48522189],\n",
       "       [ 2.37751385],\n",
       "       [-1.48522189],\n",
       "       [-1.16332725],\n",
       "       [-1.48522189],\n",
       "       [ 0.12425133],\n",
       "       [-1.16332725],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [-1.48522189],\n",
       "       [-1.48522189],\n",
       "       [ 1.08993527],\n",
       "       [ 1.41182991],\n",
       "       [ 0.44614598],\n",
       "       [-0.8414326 ],\n",
       "       [ 2.37751385],\n",
       "       [ 0.76804062],\n",
       "       [-1.48522189],\n",
       "       [-1.48522189],\n",
       "       [-0.19764331],\n",
       "       [ 0.76804062],\n",
       "       [-1.16332725],\n",
       "       [ 1.73372456],\n",
       "       [ 3.34319779],\n",
       "       [-1.48522189],\n",
       "       [-1.48522189],\n",
       "       [-0.8414326 ],\n",
       "       [-1.48522189],\n",
       "       [-0.51953796],\n",
       "       [ 2.37751385],\n",
       "       [ 1.08993527],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.76804062],\n",
       "       [ 0.44614598],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [-1.48522189],\n",
       "       [ 0.76804062],\n",
       "       [ 0.44614598],\n",
       "       [-1.48522189],\n",
       "       [-1.16332725],\n",
       "       [-0.19764331],\n",
       "       [ 0.12425133],\n",
       "       [ 1.41182991],\n",
       "       [ 0.76804062],\n",
       "       [ 0.12425133],\n",
       "       [-1.48522189],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [ 1.08993527],\n",
       "       [-0.8414326 ],\n",
       "       [ 1.08993527],\n",
       "       [-1.16332725],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.76804062],\n",
       "       [-0.19764331],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.44614598],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.76804062],\n",
       "       [-1.16332725],\n",
       "       [-1.16332725],\n",
       "       [-1.48522189],\n",
       "       [-1.48522189],\n",
       "       [ 0.12425133],\n",
       "       [-1.48522189],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.44614598],\n",
       "       [-0.8414326 ],\n",
       "       [-1.16332725],\n",
       "       [-1.16332725],\n",
       "       [-1.48522189],\n",
       "       [-1.16332725],\n",
       "       [ 0.76804062],\n",
       "       [ 2.0556192 ],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [-1.16332725],\n",
       "       [ 1.08993527],\n",
       "       [-1.48522189],\n",
       "       [-0.8414326 ],\n",
       "       [-1.48522189],\n",
       "       [ 0.44614598],\n",
       "       [-0.8414326 ],\n",
       "       [-1.48522189],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [-1.16332725],\n",
       "       [ 2.0556192 ],\n",
       "       [ 1.73372456],\n",
       "       [ 2.37751385],\n",
       "       [ 1.41182991],\n",
       "       [-1.48522189],\n",
       "       [ 0.44614598],\n",
       "       [ 1.41182991],\n",
       "       [ 2.37751385],\n",
       "       [ 0.12425133],\n",
       "       [ 1.41182991],\n",
       "       [-1.16332725],\n",
       "       [-0.8414326 ],\n",
       "       [-1.16332725],\n",
       "       [-0.19764331],\n",
       "       [ 1.41182991],\n",
       "       [ 3.02130314],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [-1.48522189],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [-1.16332725],\n",
       "       [ 1.41182991],\n",
       "       [ 0.44614598],\n",
       "       [-0.19764331],\n",
       "       [-1.48522189],\n",
       "       [-1.16332725],\n",
       "       [-1.48522189],\n",
       "       [-1.16332725],\n",
       "       [-0.8414326 ],\n",
       "       [ 1.08993527],\n",
       "       [-1.48522189],\n",
       "       [-1.48522189],\n",
       "       [ 1.41182991],\n",
       "       [-0.8414326 ],\n",
       "       [-1.48522189],\n",
       "       [-1.16332725],\n",
       "       [-1.48522189],\n",
       "       [ 0.44614598],\n",
       "       [-1.48522189],\n",
       "       [ 0.12425133],\n",
       "       [ 1.41182991],\n",
       "       [-0.8414326 ],\n",
       "       [ 2.37751385],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [-0.51953796],\n",
       "       [-1.48522189],\n",
       "       [-1.16332725],\n",
       "       [ 1.73372456],\n",
       "       [ 0.12425133],\n",
       "       [ 1.41182991],\n",
       "       [ 1.08993527],\n",
       "       [-0.8414326 ],\n",
       "       [-1.48522189],\n",
       "       [-1.16332725],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.76804062],\n",
       "       [-1.48522189],\n",
       "       [ 1.08993527],\n",
       "       [-1.48522189],\n",
       "       [-0.51953796],\n",
       "       [-1.16332725],\n",
       "       [ 2.0556192 ],\n",
       "       [ 0.12425133],\n",
       "       [-1.16332725],\n",
       "       [-0.51953796],\n",
       "       [ 0.76804062],\n",
       "       [ 0.44614598],\n",
       "       [-0.19764331],\n",
       "       [-0.8414326 ],\n",
       "       [ 2.37751385],\n",
       "       [-0.8414326 ],\n",
       "       [ 1.41182991],\n",
       "       [ 3.34319779],\n",
       "       [-1.48522189],\n",
       "       [-0.51953796],\n",
       "       [ 1.08993527],\n",
       "       [-0.51953796],\n",
       "       [-1.16332725],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [ 1.08993527],\n",
       "       [ 0.76804062],\n",
       "       [-1.48522189],\n",
       "       [-1.16332725],\n",
       "       [ 2.37751385],\n",
       "       [ 1.08993527],\n",
       "       [ 0.76804062],\n",
       "       [-1.16332725],\n",
       "       [-1.48522189],\n",
       "       [ 2.0556192 ],\n",
       "       [-1.16332725],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [-1.48522189],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [-1.16332725],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [-1.16332725],\n",
       "       [-0.8414326 ],\n",
       "       [-1.16332725],\n",
       "       [-1.48522189],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.76804062],\n",
       "       [ 3.02130314],\n",
       "       [-1.48522189],\n",
       "       [ 1.08993527],\n",
       "       [ 0.76804062],\n",
       "       [ 2.37751385],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [-0.51953796],\n",
       "       [-1.48522189],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [ 2.37751385],\n",
       "       [-0.8414326 ],\n",
       "       [-1.16332725],\n",
       "       [ 1.41182991],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [-1.16332725],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [-1.16332725],\n",
       "       [ 2.37751385],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [-1.48522189],\n",
       "       [-0.8414326 ],\n",
       "       [ 2.0556192 ],\n",
       "       [-1.16332725],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.76804062],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [-1.16332725],\n",
       "       [-1.48522189],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.12425133],\n",
       "       [-1.48522189],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [ 1.73372456],\n",
       "       [-0.51953796],\n",
       "       [-1.48522189],\n",
       "       [-1.16332725],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [ 1.08993527],\n",
       "       [-0.51953796],\n",
       "       [ 2.37751385],\n",
       "       [-1.16332725],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [ 0.76804062],\n",
       "       [ 0.12425133],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [-1.48522189],\n",
       "       [ 1.41182991],\n",
       "       [-1.48522189],\n",
       "       [ 1.73372456],\n",
       "       [-0.8414326 ],\n",
       "       [-1.48522189],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [ 1.08993527],\n",
       "       [ 1.73372456],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [-1.16332725],\n",
       "       [ 1.73372456],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [-1.48522189],\n",
       "       [ 0.76804062],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.76804062],\n",
       "       [ 0.44614598],\n",
       "       [ 1.08993527],\n",
       "       [ 0.76804062],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [ 2.37751385],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [-1.48522189],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.44614598],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.76804062],\n",
       "       [ 2.0556192 ],\n",
       "       [-1.16332725],\n",
       "       [ 2.0556192 ],\n",
       "       [ 0.76804062],\n",
       "       [-1.16332725],\n",
       "       [ 2.0556192 ],\n",
       "       [-0.51953796],\n",
       "       [-1.16332725],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [ 1.41182991],\n",
       "       [ 0.76804062],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [ 1.08993527],\n",
       "       [-1.16332725],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [ 1.08993527],\n",
       "       [-0.51953796],\n",
       "       [-0.51953796],\n",
       "       [-1.48522189],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [ 1.08993527],\n",
       "       [-0.51953796],\n",
       "       [-1.48522189],\n",
       "       [-1.16332725],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [-0.19764331],\n",
       "       [-0.51953796],\n",
       "       [ 2.37751385],\n",
       "       [ 0.44614598],\n",
       "       [ 1.41182991],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [ 0.76804062],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [ 0.76804062],\n",
       "       [ 1.41182991],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [ 0.76804062],\n",
       "       [ 0.12425133],\n",
       "       [ 1.73372456],\n",
       "       [-0.19764331],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [-0.19764331],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [ 0.76804062],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [-0.19764331],\n",
       "       [-0.51953796],\n",
       "       [ 0.44614598],\n",
       "       [ 2.0556192 ],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [ 2.37751385],\n",
       "       [ 0.44614598],\n",
       "       [-0.19764331],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [-0.19764331],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [-0.19764331],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [-1.16332725],\n",
       "       [ 0.44614598],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [ 0.44614598],\n",
       "       [-0.19764331],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [ 2.0556192 ],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [ 0.76804062],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [ 2.0556192 ],\n",
       "       [ 0.12425133],\n",
       "       [ 2.37751385],\n",
       "       [ 1.08993527],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [ 0.76804062],\n",
       "       [ 0.44614598],\n",
       "       [ 0.76804062],\n",
       "       [-1.16332725],\n",
       "       [ 1.08993527],\n",
       "       [-0.51953796],\n",
       "       [ 2.37751385],\n",
       "       [ 0.12425133],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.76804062],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [-0.8414326 ],\n",
       "       [ 1.73372456],\n",
       "       [ 1.41182991],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [-1.16332725],\n",
       "       [-0.51953796],\n",
       "       [ 1.41182991],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [-0.19764331],\n",
       "       [-0.51953796],\n",
       "       [ 0.44614598],\n",
       "       [ 0.76804062],\n",
       "       [ 2.37751385],\n",
       "       [ 0.12425133],\n",
       "       [-0.8414326 ],\n",
       "       [ 2.0556192 ],\n",
       "       [-0.51953796],\n",
       "       [ 0.44614598],\n",
       "       [ 1.41182991],\n",
       "       [ 0.12425133],\n",
       "       [-0.19764331],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [-0.19764331],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [ 1.41182991],\n",
       "       [ 0.44614598],\n",
       "       [ 0.76804062],\n",
       "       [ 2.37751385],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [ 0.44614598],\n",
       "       [-0.8414326 ],\n",
       "       [ 1.41182991],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [-1.16332725],\n",
       "       [ 1.08993527],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.12425133],\n",
       "       [-0.8414326 ],\n",
       "       [ 2.37751385],\n",
       "       [-0.19764331],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [ 0.76804062],\n",
       "       [ 0.12425133],\n",
       "       [-0.8414326 ],\n",
       "       [-1.16332725],\n",
       "       [ 1.08993527],\n",
       "       [ 0.44614598],\n",
       "       [-0.8414326 ],\n",
       "       [ 2.0556192 ],\n",
       "       [-0.19764331],\n",
       "       [-0.51953796],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [ 1.08993527],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [ 1.73372456],\n",
       "       [ 0.44614598],\n",
       "       [ 0.76804062],\n",
       "       [-0.8414326 ],\n",
       "       [ 2.37751385],\n",
       "       [-1.16332725],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 2.37751385],\n",
       "       [ 2.37751385],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [ 1.73372456],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [ 2.37751385],\n",
       "       [ 0.44614598],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.76804062],\n",
       "       [ 0.12425133],\n",
       "       [-1.16332725],\n",
       "       [ 0.12425133],\n",
       "       [-0.19764331],\n",
       "       [-0.19764331],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [-0.19764331],\n",
       "       [ 0.12425133],\n",
       "       [ 2.0556192 ],\n",
       "       [ 1.41182991],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [ 1.08993527],\n",
       "       [ 0.76804062],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [-1.48522189],\n",
       "       [-0.51953796],\n",
       "       [-0.19764331],\n",
       "       [ 0.44614598],\n",
       "       [-1.16332725],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [-0.19764331],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [-0.8414326 ],\n",
       "       [-0.19764331],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [-0.51953796],\n",
       "       [-0.51953796],\n",
       "       [-0.51953796],\n",
       "       [-1.48522189],\n",
       "       [ 0.12425133],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [-0.51953796],\n",
       "       [ 1.73372456],\n",
       "       [ 0.12425133],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.44614598],\n",
       "       [ 1.73372456],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [ 3.66509243],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [ 0.76804062],\n",
       "       [ 0.44614598],\n",
       "       [ 2.0556192 ],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [-1.16332725],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [ 2.37751385],\n",
       "       [-0.51953796],\n",
       "       [ 2.37751385],\n",
       "       [ 0.12425133],\n",
       "       [-0.19764331],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [-0.8414326 ],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [-0.8414326 ],\n",
       "       [-1.16332725],\n",
       "       [-0.19764331],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [ 0.76804062],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [-0.8414326 ],\n",
       "       [ 1.73372456],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [-0.19764331],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.44614598],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.44614598],\n",
       "       [-0.19764331],\n",
       "       [ 1.08993527],\n",
       "       [ 0.76804062],\n",
       "       [ 0.76804062],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [-1.16332725],\n",
       "       [ 0.44614598],\n",
       "       [-0.19764331],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [ 1.41182991],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [-0.19764331],\n",
       "       [-0.19764331],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [ 1.08993527],\n",
       "       [ 0.12425133],\n",
       "       [ 1.08993527],\n",
       "       [ 0.12425133],\n",
       "       [-0.19764331],\n",
       "       [-0.19764331],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [ 1.73372456],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [ 0.44614598],\n",
       "       [ 1.08993527],\n",
       "       [-0.19764331],\n",
       "       [-0.51953796],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [ 0.76804062],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [-0.19764331],\n",
       "       [-0.19764331],\n",
       "       [ 1.08993527],\n",
       "       [ 1.08993527],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [-0.51953796],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 1.08993527],\n",
       "       [ 0.12425133],\n",
       "       [ 1.41182991],\n",
       "       [ 2.0556192 ],\n",
       "       [ 0.12425133],\n",
       "       [ 1.08993527],\n",
       "       [ 0.44614598],\n",
       "       [-0.19764331],\n",
       "       [-0.19764331],\n",
       "       [ 0.76804062],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [ 0.12425133],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 0.76804062],\n",
       "       [ 0.76804062],\n",
       "       [-0.51953796],\n",
       "       [ 0.76804062],\n",
       "       [ 1.73372456],\n",
       "       [-0.51953796],\n",
       "       [ 2.37751385],\n",
       "       [ 0.12425133],\n",
       "       [-0.19764331],\n",
       "       [-0.51953796],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [-0.8414326 ],\n",
       "       [ 0.12425133],\n",
       "       [ 1.08993527],\n",
       "       [ 3.02130314],\n",
       "       [ 0.76804062],\n",
       "       [ 0.12425133],\n",
       "       [ 0.44614598],\n",
       "       [ 0.12425133],\n",
       "       [ 1.41182991],\n",
       "       [ 0.12425133]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X['Income'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf922642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class StandardScaler in module sklearn.preprocessing._data:\n",
      "\n",
      "class StandardScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      " |  StandardScaler(*, copy=True, with_mean=True, with_std=True)\n",
      " |  \n",
      " |  Standardize features by removing the mean and scaling to unit variance.\n",
      " |  \n",
      " |  The standard score of a sample `x` is calculated as:\n",
      " |  \n",
      " |      z = (x - u) / s\n",
      " |  \n",
      " |  where `u` is the mean of the training samples or zero if `with_mean=False`,\n",
      " |  and `s` is the standard deviation of the training samples or one if\n",
      " |  `with_std=False`.\n",
      " |  \n",
      " |  Centering and scaling happen independently on each feature by computing\n",
      " |  the relevant statistics on the samples in the training set. Mean and\n",
      " |  standard deviation are then stored to be used on later data using\n",
      " |  :meth:`transform`.\n",
      " |  \n",
      " |  Standardization of a dataset is a common requirement for many\n",
      " |  machine learning estimators: they might behave badly if the\n",
      " |  individual features do not more or less look like standard normally\n",
      " |  distributed data (e.g. Gaussian with 0 mean and unit variance).\n",
      " |  \n",
      " |  For instance many elements used in the objective function of\n",
      " |  a learning algorithm (such as the RBF kernel of Support Vector\n",
      " |  Machines or the L1 and L2 regularizers of linear models) assume that\n",
      " |  all features are centered around 0 and have variance in the same\n",
      " |  order. If a feature has a variance that is orders of magnitude larger\n",
      " |  than others, it might dominate the objective function and make the\n",
      " |  estimator unable to learn from other features correctly as expected.\n",
      " |  \n",
      " |  `StandardScaler` is sensitive to outliers, and the features may scale\n",
      " |  differently from each other in the presence of outliers. For an example\n",
      " |  visualization, refer to :ref:`Compare StandardScaler with other scalers\n",
      " |  <plot_all_scaling_standard_scaler_section>`.\n",
      " |  \n",
      " |  This scaler can also be applied to sparse CSR or CSC matrices by passing\n",
      " |  `with_mean=False` to avoid breaking the sparsity structure of the data.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  copy : bool, default=True\n",
      " |      If False, try to avoid a copy and do inplace scaling instead.\n",
      " |      This is not guaranteed to always work inplace; e.g. if the data is\n",
      " |      not a NumPy array or scipy.sparse CSR matrix, a copy may still be\n",
      " |      returned.\n",
      " |  \n",
      " |  with_mean : bool, default=True\n",
      " |      If True, center the data before scaling.\n",
      " |      This does not work (and will raise an exception) when attempted on\n",
      " |      sparse matrices, because centering them entails building a dense\n",
      " |      matrix which in common use cases is likely to be too large to fit in\n",
      " |      memory.\n",
      " |  \n",
      " |  with_std : bool, default=True\n",
      " |      If True, scale the data to unit variance (or equivalently,\n",
      " |      unit standard deviation).\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  scale_ : ndarray of shape (n_features,) or None\n",
      " |      Per feature relative scaling of the data to achieve zero mean and unit\n",
      " |      variance. Generally this is calculated using `np.sqrt(var_)`. If a\n",
      " |      variance is zero, we can't achieve unit variance, and the data is left\n",
      " |      as-is, giving a scaling factor of 1. `scale_` is equal to `None`\n",
      " |      when `with_std=False`.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *scale_*\n",
      " |  \n",
      " |  mean_ : ndarray of shape (n_features,) or None\n",
      " |      The mean value for each feature in the training set.\n",
      " |      Equal to ``None`` when ``with_mean=False`` and ``with_std=False``.\n",
      " |  \n",
      " |  var_ : ndarray of shape (n_features,) or None\n",
      " |      The variance for each feature in the training set. Used to compute\n",
      " |      `scale_`. Equal to ``None`` when ``with_mean=False`` and\n",
      " |      ``with_std=False``.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_samples_seen_ : int or ndarray of shape (n_features,)\n",
      " |      The number of samples processed by the estimator for each feature.\n",
      " |      If there are no missing samples, the ``n_samples_seen`` will be an\n",
      " |      integer, otherwise it will be an array of dtype int. If\n",
      " |      `sample_weights` are used it will be a float (if no missing data)\n",
      " |      or an array of dtype float that sums the weights seen so far.\n",
      " |      Will be reset on new calls to fit, but increments across\n",
      " |      ``partial_fit`` calls.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  scale : Equivalent function without the estimator API.\n",
      " |  \n",
      " |  :class:`~sklearn.decomposition.PCA` : Further removes the linear\n",
      " |      correlation across features with 'whiten=True'.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      " |  transform.\n",
      " |  \n",
      " |  We use a biased estimator for the standard deviation, equivalent to\n",
      " |  `numpy.std(x, ddof=0)`. Note that the choice of `ddof` is unlikely to\n",
      " |  affect model performance.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
      " |  >>> scaler = StandardScaler()\n",
      " |  >>> print(scaler.fit(data))\n",
      " |  StandardScaler()\n",
      " |  >>> print(scaler.mean_)\n",
      " |  [0.5 0.5]\n",
      " |  >>> print(scaler.transform(data))\n",
      " |  [[-1. -1.]\n",
      " |   [-1. -1.]\n",
      " |   [ 1.  1.]\n",
      " |   [ 1.  1.]]\n",
      " |  >>> print(scaler.transform([[2, 2]]))\n",
      " |  [[3. 3.]]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      StandardScaler\n",
      " |      sklearn.base.OneToOneFeatureMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.utils._set_output._SetOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, copy=True, with_mean=True, with_std=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None, sample_weight=None)\n",
      " |      Compute the mean and std to be used for later scaling.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y : None\n",
      " |          Ignored.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Individual weights for each sample.\n",
      " |      \n",
      " |          .. versionadded:: 0.24\n",
      " |             parameter *sample_weight* support to StandardScaler.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted scaler.\n",
      " |  \n",
      " |  inverse_transform(self, X, copy=None)\n",
      " |      Scale back the data to the original representation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data used to scale along the features axis.\n",
      " |      copy : bool, default=None\n",
      " |          Copy the input X or not.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  partial_fit(self, X, y=None, sample_weight=None)\n",
      " |      Online computation of mean and std on X for later scaling.\n",
      " |      \n",
      " |      All of X is processed as a single batch. This is intended for cases\n",
      " |      when :meth:`fit` is not feasible due to very large number of\n",
      " |      `n_samples` or because X is read from a continuous stream.\n",
      " |      \n",
      " |      The algorithm for incremental mean and std is given in Equation 1.5a,b\n",
      " |      in Chan, Tony F., Gene H. Golub, and Randall J. LeVeque. \"Algorithms\n",
      " |      for computing the sample variance: Analysis and recommendations.\"\n",
      " |      The American Statistician 37.3 (1983): 242-247:\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y : None\n",
      " |          Ignored.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Individual weights for each sample.\n",
      " |      \n",
      " |          .. versionadded:: 0.24\n",
      " |             parameter *sample_weight* support to StandardScaler.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted scaler.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.preprocessing._data.StandardScaler, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.StandardScaler\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_inverse_transform_request(self: sklearn.preprocessing._data.StandardScaler, *, copy: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.StandardScaler\n",
      " |      Request metadata passed to the ``inverse_transform`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``inverse_transform`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``inverse_transform``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``copy`` parameter in ``inverse_transform``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_partial_fit_request(self: sklearn.preprocessing._data.StandardScaler, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.StandardScaler\n",
      " |      Request metadata passed to the ``partial_fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_transform_request(self: sklearn.preprocessing._data.StandardScaler, *, copy: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.StandardScaler\n",
      " |      Request metadata passed to the ``transform`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``transform`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``transform``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``copy`` parameter in ``transform``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  transform(self, X, copy=None)\n",
      " |      Perform standardization by centering and scaling.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix of shape (n_samples, n_features)\n",
      " |          The data used to scale along the features axis.\n",
      " |      copy : bool, default=None\n",
      " |          Copy the input X or not.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.OneToOneFeatureMixin:\n",
      " |  \n",
      " |  get_feature_names_out(self, input_features=None)\n",
      " |      Get output feature names for transformation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_features : array-like of str or None, default=None\n",
      " |          Input features.\n",
      " |      \n",
      " |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      " |            used as feature names in. If `feature_names_in_` is not defined,\n",
      " |            then the following input feature names are generated:\n",
      " |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      " |          - If `input_features` is an array-like, then `input_features` must\n",
      " |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_names_out : ndarray of str objects\n",
      " |          Same as input features.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.OneToOneFeatureMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      " |      and returns a transformed version of `X`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input samples.\n",
      " |      \n",
      " |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      " |          Target values (None for unsupervised transformations).\n",
      " |      \n",
      " |      **fit_params : dict\n",
      " |          Additional fit parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  set_output(self, *, transform=None)\n",
      " |      Set output container.\n",
      " |      \n",
      " |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      " |      for an example on how to use the API.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      " |          Configure output of `transform` and `fit_transform`.\n",
      " |      \n",
      " |          - `\"default\"`: Default output format of a transformer\n",
      " |          - `\"pandas\"`: DataFrame output\n",
      " |          - `\"polars\"`: Polars output\n",
      " |          - `None`: Transform configuration is unchanged\n",
      " |      \n",
      " |          .. versionadded:: 1.4\n",
      " |              `\"polars\"` option was added.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(StandardScaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0414655",
   "metadata": {},
   "source": [
    "Есть две проблемы:\n",
    "- класc StandardScaler не умеет работать только на части колонок датафрейма\n",
    "- классы sklearn возвращают numpy arrays, а не pandas dataframe, что не удобно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "31d98491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Income', 'Children', 'Cars', 'Age']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa30d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ct = ColumnTransformer([('scaler', StandardScaler(), num_cols)], remainder = 'passthrough') # 'drop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "108fdb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5195379574051056, -0.5586728696623785, -1.2916513760469168,\n",
       "        ..., 'Yes', '0-1 Miles', 'Europe'],\n",
       "       [-0.8414326026375131, 0.6718841119728166, -0.4020843126537234,\n",
       "        ..., 'Yes', '0-1 Miles', 'Europe'],\n",
       "       [0.7680406235245242, 1.9024410936080116, 0.48748275073947, ...,\n",
       "        'No', '2-5 Miles', 'Europe'],\n",
       "       ...,\n",
       "       [0.12425133305970927, 0.05660562115521903, -1.2916513760469168,\n",
       "        ..., 'Yes', '0-1 Miles', 'North America'],\n",
       "       [1.4118299139893389, 0.6718841119728166, 1.3770498141326635, ...,\n",
       "        'No', '1-2 Miles', 'North America'],\n",
       "       [0.12425133305970927, 0.6718841119728166, 0.48748275073947, ...,\n",
       "        'Yes', '10+ Miles', 'North America']], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e56049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# нет удобной реализации - напишем сами !\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class CustomScaler(TransformerMixin):\n",
    "    def __init__(self, cols, scaler = None):\n",
    "        self.cols = cols\n",
    "        self.scaler = scaler or StandardScaler() \n",
    "    def fit(self, X, y = None):\n",
    "        num_cols = X.copy()[self.cols]\n",
    "        self.scaler.fit(num_cols)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_res = X.copy()\n",
    "        num_cols_tr = self.scaler.transform(X_res[self.cols])\n",
    "        for i, col in enumerate(self.cols):\n",
    "            X_res[col] = num_cols_tr[:,i]\n",
    "        return X_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2f03ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = CustomScaler(num_cols)\n",
    "X2 = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "da904823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Education</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Home Owner</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Commute Distance</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>40000</td>\n",
       "      <td>1</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Skilled Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>80000</td>\n",
       "      <td>5</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Professional</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>5-10 Miles</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>30000</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Marital Status  Gender  Income  Children        Education      Occupation  \\\n",
       "0        Married  Female   40000         1        Bachelors  Skilled Manual   \n",
       "1        Married    Male   30000         3  Partial College        Clerical   \n",
       "2        Married    Male   80000         5  Partial College    Professional   \n",
       "3         Single    Male   70000         0        Bachelors    Professional   \n",
       "4         Single    Male   30000         0        Bachelors        Clerical   \n",
       "\n",
       "  Home Owner  Cars Commute Distance   Region  Age  \n",
       "0        Yes     0        0-1 Miles   Europe   42  \n",
       "1        Yes     1        0-1 Miles   Europe   43  \n",
       "2         No     2        2-5 Miles   Europe   60  \n",
       "3        Yes     1       5-10 Miles  Pacific   41  \n",
       "4         No     0        0-1 Miles   Europe   36  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aeec28cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Education</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Home Owner</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Commute Distance</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>-0.519538</td>\n",
       "      <td>-0.558673</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Skilled Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-1.291651</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>-0.192988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>-0.841433</td>\n",
       "      <td>0.671884</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.402084</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>-0.104866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.768041</td>\n",
       "      <td>1.902441</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Professional</td>\n",
       "      <td>No</td>\n",
       "      <td>0.487483</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>1.393214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.446146</td>\n",
       "      <td>-1.173951</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.402084</td>\n",
       "      <td>5-10 Miles</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>-0.281110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>-0.841433</td>\n",
       "      <td>-1.173951</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>No</td>\n",
       "      <td>-1.291651</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>-0.721722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Marital Status  Gender    Income  Children        Education      Occupation  \\\n",
       "0        Married  Female -0.519538 -0.558673        Bachelors  Skilled Manual   \n",
       "1        Married    Male -0.841433  0.671884  Partial College        Clerical   \n",
       "2        Married    Male  0.768041  1.902441  Partial College    Professional   \n",
       "3         Single    Male  0.446146 -1.173951        Bachelors    Professional   \n",
       "4         Single    Male -0.841433 -1.173951        Bachelors        Clerical   \n",
       "\n",
       "  Home Owner      Cars Commute Distance   Region       Age  \n",
       "0        Yes -1.291651        0-1 Miles   Europe -0.192988  \n",
       "1        Yes -0.402084        0-1 Miles   Europe -0.104866  \n",
       "2         No  0.487483        2-5 Miles   Europe  1.393214  \n",
       "3        Yes -0.402084       5-10 Miles  Pacific -0.281110  \n",
       "4         No -1.291651        0-1 Miles   Europe -0.721722  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df6e872",
   "metadata": {},
   "source": [
    "# Соберем все преобразования данных в pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba1d0eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "p1 = Pipeline([\n",
    "    ('ordinal_encoder_', OrdinalEncoder(cols=ordinal_cols + binary_cols + cat_cols)), # плохо!!!\n",
    "    ('scaler_', CustomScaler(num_cols)),\n",
    "    ('model_', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "p2 = Pipeline([\n",
    "    ('one_hot_encoder_', OneHotEncoder(cols=ordinal_cols + binary_cols+cat_cols)),\n",
    "    ('scaler_', CustomScaler(num_cols)),\n",
    "    ('model_', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "p3 = Pipeline([\n",
    "    ('target_encoder_', TargetEncoder(cols=ordinal_cols + binary_cols+cat_cols)),\n",
    "    ('scaler_', CustomScaler(num_cols)),\n",
    "    ('model_', LogisticRegression())\n",
    "])\n",
    "\n",
    "p4 = Pipeline([\n",
    "    ('ordinal_encoder_', OrdinalEncoder(cols=ordinal_cols)),\n",
    "    ('one_hot_encoder_', OneHotEncoder(cols=binary_cols+cat_cols)),\n",
    "    ('scaler_', CustomScaler(num_cols)),\n",
    "    ('model_', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "p5 = Pipeline([\n",
    "    ('ordinal_encoder_', OrdinalEncoder(cols=ordinal_cols)),\n",
    "    ('one_hot_encoder_', OneHotEncoder(cols=binary_cols)),\n",
    "    ('target_encoder_', TargetEncoder(cols=cat_cols)),\n",
    "    ('scaler_', CustomScaler(num_cols)),\n",
    "    ('model_', LogisticRegression())\n",
    "])\n",
    "\n",
    "p6 = Pipeline([\n",
    "    ('one_hot_encoder_', OneHotEncoder(cols=binary_cols)),\n",
    "    ('target_encoder_', TargetEncoder(cols=cat_cols + ordinal_cols)),\n",
    "    ('scaler_', CustomScaler(num_cols)),\n",
    "    ('model_', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9cf3065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.596\n"
     ]
    }
   ],
   "source": [
    "# пример работы с пайплайном\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "p1.fit(X_train, y_train)\n",
    "\n",
    "#print(p1)\n",
    "\n",
    "y_pred = p1.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c4670",
   "metadata": {},
   "source": [
    "# Сравнение качества классификации при разных пайплайнах преобразования данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0dc93e",
   "metadata": {},
   "source": [
    "Вообще существует довольно большое количество метрик для задачи бинарной классификации (о них будет подробно рассказано на лекциях)\n",
    "\n",
    "Но для нашей задачи разберем самую простую и интуитивную метрику: accuracy\n",
    "\n",
    "$accuracy = \\frac{1}{n}\\Sigma_{i=0}^n [\\hat y_i == y_i]$\n",
    "\n",
    "То есть доля правильных предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee526e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "22e4cfd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline 1: mean cv accuracy = 0.629\n",
      "Pipeline 2: mean cv accuracy = 0.617\n",
      "Pipeline 3: mean cv accuracy = 0.629\n",
      "Pipeline 4: mean cv accuracy = 0.618\n",
      "Pipeline 5: mean cv accuracy = 0.619\n",
      "Pipeline 6: mean cv accuracy = 0.6140000000000001\n"
     ]
    }
   ],
   "source": [
    "for i, pipe in enumerate([p1, p2, p3, p4, p5, p6]):\n",
    "    cv_res = cross_validate(pipe,\n",
    "                            X,\n",
    "                            y,\n",
    "                            cv = 5,\n",
    "                            scoring = 'accuracy'\n",
    "                           )\n",
    "    print(f\"Pipeline {i + 1}: mean cv accuracy = {cv_res['test_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b10f2a2",
   "metadata": {},
   "source": [
    "Больше про то, как задавать поле поиска и какие еще есть методы оптимизации гиперпараметров можете прочитать здесь\n",
    "\n",
    "https://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828865ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
